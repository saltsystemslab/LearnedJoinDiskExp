{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['command', 'run', 'dataset', 'op', 'input_size', 'result.checksum',\n",
      "       'result.duration_ns', 'result.duration_sec', 'result.inner_disk_fetch',\n",
      "       'result.inner_disk_fetch_size', 'result.inner_total_bytes_fetched',\n",
      "       'result.outer_disk_fetch', 'result.outer_disk_fetch_size',\n",
      "       'result.outer_total_bytes_fetched', 'spec.algo', 'spec.algo_name',\n",
      "       'spec.check_checksum', 'spec.common_key',\n",
      "       'spec.index.leaf_size_in_pages', 'spec.index.search', 'spec.index.type',\n",
      "       'spec.inner_table', 'spec.key_size', 'spec.key_type',\n",
      "       'spec.load_sstable_in_mem', 'spec.name', 'spec.num_threads',\n",
      "       'spec.outer_table', 'spec.result_path', 'spec.value_size',\n",
      "       'spec.write_result_to_disk'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "import json;\n",
    "import builtins\n",
    "import pandas as pd;\n",
    "import duckdb\n",
    "\n",
    "dir = '/home/chesetti/Repos/learned_merge_cleanup/sponge'\n",
    "op = ['join', 'merge']\n",
    "#datasets = ['fb', 'wiki', 'uniform_dense', 'uniform_sparse', 'normal', 'lognormal', 'osm', 'books']\n",
    "#threads = [\"1\", \"4\", \"16\", \"32\"]\n",
    "datasets = ['str']\n",
    "threads = [\"1\", \"4\", \"16\", \"32\"]\n",
    "for op in op:\n",
    "    for dataset in datasets:\n",
    "        for thread in threads:\n",
    "            testdir = os.path.join(dir, \"_\".join([op, dataset, thread]), \"outputs\", \"results\")\n",
    "            if (not os.path.exists(testdir)):\n",
    "                continue\n",
    "            rundirs = os.listdir(testdir)\n",
    "            for rundir in rundirs:\n",
    "                for test_result_file in os.listdir(os.path.join(testdir, rundir)):\n",
    "                    json_file = builtins.open(os.path.join(testdir, rundir, test_result_file))\n",
    "                    test_result = json.load(json_file)\n",
    "                    test_result['run'] = rundir\n",
    "                    test_result['dataset'] = dataset\n",
    "                    test_result['op'] = op\n",
    "                    if dataset == 'osm' or dataset == 'books':\n",
    "                        test_result['input_size'] = 800_000_000 \n",
    "                    elif dataset == 'str':\n",
    "                        test_result['input_size'] = 100_000_000\n",
    "                    else:\n",
    "                        test_result['input_size'] = 200_000_000 \n",
    "                    test_results.append(test_result)\n",
    "                    json_file.close()\n",
    "test_dataframe = pd.json_normalize(test_results)\n",
    "print(test_dataframe.columns)\n",
    "test_dataframe = test_dataframe.dropna(subset=['command'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>input_size</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>threads</th>\n",
       "      <th>ratio</th>\n",
       "      <th>op</th>\n",
       "      <th>algo</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_type</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>inner_bytes_fetched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree1024</td>\n",
       "      <td>btree1024</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>1024</td>\n",
       "      <td>16.654654</td>\n",
       "      <td>1.600029e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree256</td>\n",
       "      <td>btree256</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>256</td>\n",
       "      <td>18.127506</td>\n",
       "      <td>1.600004e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree256</td>\n",
       "      <td>btree256</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>256</td>\n",
       "      <td>17.779150</td>\n",
       "      <td>1.600004e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>join</td>\n",
       "      <td>pgm256</td>\n",
       "      <td>pgm256</td>\n",
       "      <td>PGM</td>\n",
       "      <td>256</td>\n",
       "      <td>2.839688</td>\n",
       "      <td>1.599984e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>join</td>\n",
       "      <td>pgm256</td>\n",
       "      <td>pgm256</td>\n",
       "      <td>PGM</td>\n",
       "      <td>256</td>\n",
       "      <td>4.856526</td>\n",
       "      <td>1.600008e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>merge</td>\n",
       "      <td>pgm2048</td>\n",
       "      <td>pgm2048</td>\n",
       "      <td>PGM</td>\n",
       "      <td>2048</td>\n",
       "      <td>3.107213</td>\n",
       "      <td>3.200004e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>merge</td>\n",
       "      <td>pgm1024</td>\n",
       "      <td>pgm1024</td>\n",
       "      <td>PGM</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.663677</td>\n",
       "      <td>3.200006e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>merge</td>\n",
       "      <td>standard_merge</td>\n",
       "      <td>standard_merge</td>\n",
       "      <td>SM</td>\n",
       "      <td>0</td>\n",
       "      <td>3.116753</td>\n",
       "      <td>3.200006e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>merge</td>\n",
       "      <td>pgm256</td>\n",
       "      <td>pgm256</td>\n",
       "      <td>PGM</td>\n",
       "      <td>256</td>\n",
       "      <td>2.654987</td>\n",
       "      <td>3.200006e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>merge</td>\n",
       "      <td>pgm256</td>\n",
       "      <td>pgm256</td>\n",
       "      <td>PGM</td>\n",
       "      <td>256</td>\n",
       "      <td>2.707481</td>\n",
       "      <td>3.200004e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3976 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset   input_size dataset_type  threads  ratio     op            algo  \\\n",
       "3        str  100000000.0    SYNTHETIC      1.0    5.0   join       btree1024   \n",
       "4        str  100000000.0    SYNTHETIC      1.0    5.0   join        btree256   \n",
       "5        str  100000000.0    SYNTHETIC      1.0    5.0   join        btree256   \n",
       "6        str  100000000.0    SYNTHETIC      1.0   10.0   join          pgm256   \n",
       "7        str  100000000.0    SYNTHETIC      1.0    5.0   join          pgm256   \n",
       "...      ...          ...          ...      ...    ...    ...             ...   \n",
       "3974     str  100000000.0    SYNTHETIC      4.0    5.0  merge         pgm2048   \n",
       "3975     str  100000000.0    SYNTHETIC      4.0   50.0  merge         pgm1024   \n",
       "3976     str  100000000.0    SYNTHETIC      4.0  100.0  merge  standard_merge   \n",
       "3977     str  100000000.0    SYNTHETIC      4.0  100.0  merge          pgm256   \n",
       "3978     str  100000000.0    SYNTHETIC      4.0   10.0  merge          pgm256   \n",
       "\n",
       "          index_name index_type  epsilon  duration_sec  inner_bytes_fetched  \n",
       "3          btree1024      BTREE     1024     16.654654         1.600029e+09  \n",
       "4           btree256      BTREE      256     18.127506         1.600004e+09  \n",
       "5           btree256      BTREE      256     17.779150         1.600004e+09  \n",
       "6             pgm256        PGM      256      2.839688         1.599984e+09  \n",
       "7             pgm256        PGM      256      4.856526         1.600008e+09  \n",
       "...              ...        ...      ...           ...                  ...  \n",
       "3974         pgm2048        PGM     2048      3.107213         3.200004e+09  \n",
       "3975         pgm1024        PGM     1024      2.663677         3.200006e+09  \n",
       "3976  standard_merge         SM        0      3.116753         3.200006e+09  \n",
       "3977          pgm256        PGM      256      2.654987         3.200006e+09  \n",
       "3978          pgm256        PGM      256      2.707481         3.200004e+09  \n",
       "\n",
       "[3976 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = {\n",
    "    \"pgm256\": 256,\n",
    "    \"pgm1024\": 1024,\n",
    "    \"pgm2048\": 2048,\n",
    "    \"btree256\": 256,\n",
    "    \"btree512\": 512,\n",
    "    \"btree1024\": 1024,\n",
    "    \"btree1048\": 1024,\n",
    "    \"btree2048\": 2048,\n",
    "    \"hashjoin\": 0,\n",
    "    \"btree\": 0,\n",
    "    \"sj\": 0,\n",
    "    \"sj2\": 0,\n",
    "    \"standard_merge\": 0\n",
    "};\n",
    "indexType = {\n",
    "    \"pgm64\": \"PGM\",\n",
    "    \"pgm128\": \"PGM\",\n",
    "    \"pgm256\": \"PGM\",\n",
    "    \"pgm512\": \"PGM\",\n",
    "    \"pgm1024\": \"PGM\",\n",
    "    \"pgm2048\": \"PGM\",\n",
    "    \"btree256\": \"BTREE\",\n",
    "    \"btree512\": \"BTREE\",\n",
    "    \"btree1024\": \"BTREE\",\n",
    "    \"btree1048\": \"BTREE\",\n",
    "    \"btree2048\": \"BTREE\",\n",
    "    \"hashjoin\": \"NA\",\n",
    "    \"btree\": 0,\n",
    "    \"sj\": \"SJ\",\n",
    "    \"sj2\": \"NA\",\n",
    "    \"standard_merge\": \"SM\"\n",
    "};\n",
    "dataset_type = {\n",
    "    \"fb\": \"REAL\",\n",
    "    \"wiki\": \"REAL\",\n",
    "    \"osm\": \"REAL\",\n",
    "    \"books\": \"REAL\",\n",
    "    \"uniform_dense\": \"SYNTHETIC\",\n",
    "    \"uniform_sparse\": \"SYNTHETIC\",\n",
    "    \"normal\": \"SYNTHETIC\",\n",
    "    \"lognormal\": \"SYNTHETIC\",\n",
    "    \"str\": \"SYNTHETIC\"\n",
    "};\n",
    "dataset_display = {\n",
    "    \"fb\": \"fb\",\n",
    "    \"wiki\": \"wiki\",\n",
    "    \"osm\": \"osm\",\n",
    "    \"books\": \"books\",\n",
    "    \"uniform_dense\": \"udense\",\n",
    "    \"uniform_sparse\": \"usparse\",\n",
    "    \"normal\": \"normal\",\n",
    "    \"lognormal\": \"lognormal\",\n",
    "    \"str\": \"16 Byte Strings\"\n",
    "};\n",
    "dataset_order = {\n",
    "    \"fb\": 0,\n",
    "    \"wiki\": 1,\n",
    "    \"osm\": 2,\n",
    "    \"books\": 3,\n",
    "    \"uniform_dense\": 4,\n",
    "    \"uniform_sparse\": 5,\n",
    "    \"normal\": 6,\n",
    "    \"lognormal\": 7,\n",
    "};\n",
    "\n",
    "test_dataframe[\"threads\"] = test_dataframe[\"spec.num_threads\"]\n",
    "test_dataframe[\"duration_sec\"] = test_dataframe[\"result.duration_ns\"] / (1000000000)\n",
    "test_dataframe[\"ratio\"] = test_dataframe[\"spec.common_key\"]\n",
    "test_dataframe[\"algo\"] = test_dataframe[\"spec.algo_name\"]\n",
    "test_dataframe[\"inner_bytes_fetched\"] = test_dataframe[\"result.inner_total_bytes_fetched\"]\n",
    "test_dataframe[\"epsilon\"] = test_dataframe[\"spec.algo_name\"].map(lambda x: epsilon[str(x).lower()])\n",
    "test_dataframe[\"index_type\"] = test_dataframe[\"spec.algo_name\"].map(lambda x: indexType[str(x).lower()])\n",
    "test_dataframe[\"index_name\"] = test_dataframe[\"spec.algo_name\"]\n",
    "test_dataframe[\"dataset_type\"] = test_dataframe[\"dataset\"].map(lambda x: dataset_type[str(x).lower()])\n",
    "\n",
    "results = test_dataframe[[\"dataset\", \"input_size\", \"dataset_type\", \"threads\", \"ratio\", \"op\", \"algo\", \"index_name\", \"index_type\", \"epsilon\", \"duration_sec\", \"inner_bytes_fetched\"]]\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      "ratio & SJ_0 & BTREE_256 & BTREE_2048 & PGM_256 & PGM_2048 \\\\\n",
      "\\midrule\n",
      "1.000 & 11.372 & 107.323 & 83.056 & 24.924 & 27.118 \\\\\n",
      "5.000 & 3.157 & 17.953 & 14.105 & 4.683 & 5.046 \\\\\n",
      "10.000 & 2.203 & 10.051 & 7.921 & 2.833 & 3.344 \\\\\n",
      "50.000 & 1.314 & 2.416 & 1.924 & 0.847 & 0.882 \\\\\n",
      "100.000 & 1.184 & 1.392 & 1.435 & 0.717 & 0.704 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average results by time.\n",
    "input_size = 100_000_000\n",
    "rows = duckdb.sql(\n",
    "    \" SELECT ratio, epsilon, op, index_type, AVG(duration_sec) as v FROM results \"\n",
    "    f\" WHERE threads = 1 AND input_size={input_size} AND op='join' AND index_type!='NA'\"\n",
    "    \" GROUP BY ratio, threads, op, input_size, index_type, epsilon\"\n",
    "    \" ORDER BY ratio, threads, epsilon\"\n",
    ")\n",
    "p = (duckdb.sql(\"PIVOT rows ON index_type,epsilon USING avg(v) GROUP BY ratio ORDER BY RATIO\"))\n",
    "print(p.df()[['ratio', 'SJ_0', 'BTREE_256', 'BTREE_2048', 'PGM_256', 'PGM_2048']].to_latex(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrr}\n",
      "\\toprule\n",
      "threads & ratio & btree2048 & pgm2048 & sj \\\\\n",
      "\\midrule\n",
      "1.000 & 10.000 & 7.921 & 3.344 & 2.203 \\\\\n",
      "1.000 & 50.000 & 1.924 & 0.882 & 1.314 \\\\\n",
      "1.000 & 100.000 & 1.435 & 0.704 & 1.184 \\\\\n",
      "4.000 & 10.000 & 2.477 & 1.072 & 0.713 \\\\\n",
      "4.000 & 50.000 & 0.674 & 0.272 & 0.443 \\\\\n",
      "4.000 & 100.000 & 0.376 & 0.194 & 0.337 \\\\\n",
      "8.000 & 10.000 & 1.651 & 0.689 & 0.548 \\\\\n",
      "8.000 & 50.000 & 0.395 & 0.221 & 0.324 \\\\\n",
      "8.000 & 100.000 & 0.269 & 0.151 & 0.280 \\\\\n",
      "32.000 & 10.000 & 0.786 & 0.489 & 0.498 \\\\\n",
      "32.000 & 50.000 & 0.289 & 0.236 & 0.277 \\\\\n",
      "32.000 & 100.000 & 0.233 & 0.192 & 0.244 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = duckdb.sql(\n",
    "    \" SELECT ratio, threads, epsilon, op, index_name, AVG(duration_sec) as v FROM results \"\n",
    "    \" WHERE (ratio=10 or ratio=50 or ratio=100) AND input_size=100000000 AND op='join' AND index_type!='NA'\"\n",
    "    \" AND (index_name='sj' OR epsilon=2048)\"\n",
    "    \" GROUP BY ratio, threads, op, input_size, index_name, epsilon\"\n",
    "    \" ORDER BY ratio, threads, epsilon\"\n",
    ")\n",
    "rows\n",
    "print(duckdb.sql(\"PIVOT rows ON index_name USING AVG(v) GROUP BY threads,ratio ORDER BY threads,ratio\").df().to_latex(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬─────────┬────────────────────┬────────────────────┬───┬────────────────────┬─────────┬─────────┬────────┐\n",
      "│ ratio  │ BTREE_0 │     BTREE_1024     │     BTREE_2048     │ … │        SM_0        │ SM_1024 │ SM_2048 │ SM_256 │\n",
      "│ double │ double  │       double       │       double       │   │       double       │ double  │ double  │ double │\n",
      "├────────┼─────────┼────────────────────┼────────────────────┼───┼────────────────────┼─────────┼─────────┼────────┤\n",
      "│    1.0 │    NULL │ 3.6445897333333335 │ 3.4949636130000004 │ … │        4.200778664 │    NULL │    NULL │   NULL │\n",
      "│    2.0 │    NULL │        3.174356543 │ 3.0832515753333336 │ … │  4.157332778333333 │    NULL │    NULL │   NULL │\n",
      "│    5.0 │    NULL │ 17.858731408333337 │ 15.152702550333338 │ … │ 5.2472953586666655 │    NULL │    NULL │   NULL │\n",
      "│   10.0 │    NULL │ 11.098453535333332 │        9.608938701 │ … │  4.685297184999998 │    NULL │    NULL │   NULL │\n",
      "│   50.0 │    NULL │  4.550107063000001 │  4.232528185333333 │ … │  4.240682679000001 │    NULL │    NULL │   NULL │\n",
      "│  100.0 │    NULL │  3.846495353666666 │ 3.5271673953333336 │ … │        4.198268139 │    NULL │    NULL │   NULL │\n",
      "├────────┴─────────┴────────────────────┴────────────────────┴───┴────────────────────┴─────────┴─────────┴────────┤\n",
      "│ 6 rows                                                                                      13 columns (8 shown) │\n",
      "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "\\begin{tabular}{rrrrrr}\n",
      "\\toprule\n",
      "ratio & SM_0 & BTREE_256 & BTREE_2048 & PGM_256 & PGM_2048 \\\\\n",
      "\\midrule\n",
      "1.000 & 4.201 & 3.741 & 3.495 & 2.948 & 2.942 \\\\\n",
      "2.000 & 4.157 & 3.213 & 3.083 & 3.022 & 2.825 \\\\\n",
      "5.000 & 5.247 & 19.663 & 15.153 & 6.533 & 6.333 \\\\\n",
      "10.000 & 4.685 & 12.102 & 9.609 & 5.039 & 4.793 \\\\\n",
      "50.000 & 4.241 & 4.785 & 4.233 & 3.241 & 3.169 \\\\\n",
      "100.000 & 4.198 & 3.781 & 3.527 & 3.174 & 2.960 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = duckdb.sql(\n",
    "    \" SELECT ratio, epsilon, op, index_type, AVG(duration_sec) as v FROM results \"\n",
    "    \" WHERE threads = 1 AND input_size=100000000 AND op='merge' AND index_type!='NA'\"\n",
    "    \" GROUP BY ratio, threads, op, input_size, index_type, epsilon\"\n",
    "    \" ORDER BY ratio, threads, epsilon\"\n",
    ")\n",
    "p = (duckdb.sql(\"PIVOT rows ON index_type,epsilon USING avg(v) GROUP BY ratio ORDER BY RATIO\"))\n",
    "print(p)\n",
    "print(p.df()[['ratio', 'SM_0', 'BTREE_256', 'BTREE_2048', 'PGM_256', 'PGM_2048']].to_latex(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      "threads & ratio & btree2048 & pgm2048 \\\\\n",
      "\\midrule\n",
      "1 & 10 & 6.245 & 4.826 \\\\\n",
      "1 & 50 & 3.518 & 3.243 \\\\\n",
      "1 & 100 & 3.117 & 2.979 \\\\\n",
      "4 & 10 & 2.702 & 2.647 \\\\\n",
      "4 & 50 & 2.500 & 2.641 \\\\\n",
      "4 & 100 & 2.532 & 2.436 \\\\\n",
      "16 & 10 & 2.722 & 2.705 \\\\\n",
      "16 & 50 & 2.550 & 2.514 \\\\\n",
      "16 & 100 & 2.509 & 2.491 \\\\\n",
      "32 & 10 & 2.900 & 2.949 \\\\\n",
      "32 & 50 & 2.703 & 2.767 \\\\\n",
      "32 & 100 & 2.749 & 2.730 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = duckdb.sql(\n",
    "    \" SELECT ratio, threads, epsilon, op, index_name, AVG(duration_sec) as v FROM results \"\n",
    "    \" WHERE (ratio=10 or ratio=50 or ratio=100) AND input_size=200000000 AND op='merge' AND index_type!='NA'\"\n",
    "    \" AND (index_name='standard_merge' OR epsilon=2048)\"\n",
    "    \" GROUP BY ratio, threads, op, input_size, index_name, epsilon\"\n",
    "    \" ORDER BY ratio, threads, epsilon\"\n",
    ")\n",
    "rows\n",
    "print(duckdb.sql(\"PIVOT rows ON index_name USING AVG(v) GROUP BY threads,ratio ORDER BY threads,ratio\").df().to_latex(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_threads(op, ratio):\n",
    "    rows = duckdb.sql(\n",
    "        \" SELECT ratio,index_name,threads, MEDIAN(duration) as v\"\n",
    "        f\" FROM results where op='{op}' AND ratio={ratio}  AND index_type!='NA'\"\n",
    "        \" GROUP BY dataset, ratio, index_name, threads \"\n",
    "        \" ORDER BY Threads\")\n",
    "    return duckdb.sql('PIVOT rows ON index_name USING MEDIAN(v)')\n",
    "ratios = [10, 50, 100]\n",
    "for ratio in ratios:\n",
    "    for op in ['join', 'merge']:\n",
    "        group_by_threads(op, ratio).df().to_csv('_'.join([op, str(ratio), 'threadStudy.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGM Index Memory Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_btree_pgm_memory(epsilon, thread, dataset_type):\n",
    "        where = f\"WHERE threads={thread} AND epsilon={epsilon} AND ratio=10 \"\n",
    "        if dataset_type != \"all\":\n",
    "                where = where + f\" AND dataset_type='{dataset_type}' \"\n",
    "        query = (\"SELECT ratio, threads, algo, index_type, dataset, dataset_type,\"\n",
    "                \"epsilon, MEAN(index_memory) as memory_mean, FROM results \" \n",
    "                + where +\n",
    "                \"GROUP BY (ratio, threads, algo, index_type, epsilon, dataset, dataset_type) \"\n",
    "                \"ORDER BY ratio\")\n",
    "        subresult = duckdb.sql(query)\n",
    "        df = duckdb.sql(\"PIVOT subresult ON index_type USING MEAN(memory_mean) GROUP BY ratio,dataset\").df()\n",
    "        df['REL'] = (df['PGM']) / df['BTREE']\n",
    "        return df\n",
    "\n",
    "def compare_btree_pgm_build_duration(epsilon, thread, dataset_type):\n",
    "        where = f\"WHERE threads={thread} AND epsilon={epsilon} AND ratio=10 \"\n",
    "        if dataset_type != \"all\":\n",
    "                where = where + f\" AND dataset_type='{dataset_type}' \"\n",
    "        query = (\"SELECT ratio, threads, algo, index_type, dataset, dataset_type,\"\n",
    "                \"epsilon, MEAN(index_build_duration) as index_build_duration, FROM results \" \n",
    "                + where +\n",
    "                \"GROUP BY (ratio, threads, algo, index_type, epsilon, dataset, dataset_type) \"\n",
    "                \"ORDER BY ratio\")\n",
    "        subresult = duckdb.sql(query)\n",
    "        df = duckdb.sql(\"PIVOT subresult ON index_type USING MEAN(index_build_duration) GROUP BY ratio,dataset\").df()\n",
    "        df['REL'] = (df['PGM']) / df['BTREE']\n",
    "        return df\n",
    "dict = []\n",
    "dict.append({\n",
    "        'epsilon':256, \n",
    "        'ALL': compare_btree_pgm_memory(epsilon=256, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_memory(epsilon=256, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_memory(epsilon=256, thread=1, dataset_type='SYNTHETIC')['REL'].mean(),\n",
    "        'ACTUAL': compare_btree_pgm_memory(epsilon=256, thread=1, dataset_type='all')['PGM'].mean(),\n",
    "        })\n",
    "dict.append({\n",
    "        'epsilon':1024, \n",
    "        'ALL': compare_btree_pgm_memory(epsilon=1024, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_memory(epsilon=1024, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_memory(epsilon=1024, thread=1, dataset_type='SYNTHETIC')['REL'].mean(),\n",
    "        'ACTUAL': compare_btree_pgm_memory(epsilon=1024, thread=1, dataset_type='all')['PGM'].mean(),\n",
    "        })\n",
    "dict.append({\n",
    "        'epsilon': 2048, \n",
    "        'ALL': compare_btree_pgm_memory(epsilon=2048, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_memory(epsilon=2048, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_memory(epsilon=2048, thread=1, dataset_type='SYNTHETIC')['REL'].mean(),\n",
    "        'ACTUAL': compare_btree_pgm_memory(epsilon=2048, thread=1, dataset_type='all')['PGM'].mean(),\n",
    "        })\n",
    "\n",
    "print(pd.DataFrame(dict).to_latex(index=False))\n",
    "\n",
    "dict = []\n",
    "dict.append({\n",
    "        'epsilon':256, \n",
    "        'ALL': compare_btree_pgm_build_duration(epsilon=256, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_build_duration(epsilon=256, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_build_duration(epsilon=256, thread=1, dataset_type='SYNTHETIC')['REL'].mean()\n",
    "        })\n",
    "dict.append({\n",
    "        'epsilon':1024, \n",
    "        'ALL': compare_btree_pgm_build_duration(epsilon=1024, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_build_duration(epsilon=1024, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_build_duration(epsilon=1024, thread=1, dataset_type='SYNTHETIC')['REL'].mean()\n",
    "        })\n",
    "dict.append({\n",
    "        'epsilon': 2048, \n",
    "        'ALL': compare_btree_pgm_build_duration(epsilon=2048, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_build_duration(epsilon=2048, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_build_duration(epsilon=2048, thread=1, dataset_type='SYNTHETIC')['REL'].mean()\n",
    "        })\n",
    "print(pd.DataFrame(dict).to_latex(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGM vs TREE SJ same epsilon (Duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_btree_pgm_duration(epsilon, thread, dataset, op):\n",
    "        where = f\"WHERE threads={thread} AND op='{op}' AND (epsilon={epsilon} OR algo='sj' OR algo='standard_merge')\"\n",
    "        if dataset != \"all\":\n",
    "                where = where + f\"AND dataset='{dataset}'\"\n",
    "        query = (\"SELECT ratio, threads, algo, index_type,\"\n",
    "                \"epsilon, MEDIAN(duration) as duration_mean, FROM results \" \n",
    "                + where +\n",
    "                \"GROUP BY (ratio, threads, algo, index_type, epsilon) \"\n",
    "                \"ORDER BY ratio\")\n",
    "        subresult = duckdb.sql(query)\n",
    "        print(subresult)\n",
    "        df = duckdb.sql(\"PIVOT subresult ON index_type USING sum(duration_mean) GROUP BY ratio\").df()\n",
    "        print(df)\n",
    "        baseline = 'SJ' if op == 'join' else 'SM'\n",
    "        df['RATIO'] = df['ratio']\n",
    "        if 'PGM' in df.columns:\n",
    "                df['PGM_REL'] = (df['PGM']/ df[baseline])\n",
    "        if 'BTREE' in df.columns:\n",
    "                df['BTREE_REL'] = (df['BTREE']/ df[baseline])\n",
    "        return df\n",
    "\n",
    "def compare_pgm_bytes_fetched(epsilon, thread, dataset, op):\n",
    "        where = f\"WHERE threads={thread} AND op='{op}' AND (epsilon={epsilon} OR algo='sj' OR algo='standard_merge')\"\n",
    "        if dataset != \"all\":\n",
    "                where = where + f\"AND dataset='{dataset}'\"\n",
    "        query = (\"SELECT ratio, threads, algo, index_type,\"\n",
    "                \"epsilon, MEDIAN(inner_bytes_fetched) as median, FROM results \" \n",
    "                + where +\n",
    "                \"GROUP BY (ratio, threads, algo, index_type, epsilon) \"\n",
    "                \"ORDER BY ratio\")\n",
    "        subresult = duckdb.sql(query)\n",
    "        df = duckdb.sql(\"PIVOT subresult ON index_type USING AVG(median) GROUP BY ratio\").df()\n",
    "        baseline = 'SJ' if op == 'join' else 'SM'\n",
    "        df['RATIO'] = df['ratio']\n",
    "        df['BTREE_REL'] = (df['BTREE']/ df[baseline])\n",
    "        df['PGM_REL'] = (df['PGM']/ df[baseline])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame();\n",
    "df['ratio'] = (compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='join')['RATIO'])\n",
    "df['t=1'] = (compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=4'] = (compare_btree_pgm_duration(epsilon=2048, thread=4, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=16'] = (compare_btree_pgm_duration(epsilon=2048, thread=16, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=32'] = (compare_btree_pgm_duration(epsilon=2048, thread=32, dataset='all', op='join')['PGM_REL'])\n",
    "print(df.to_latex(index=False))\n",
    "\n",
    "df = pd.DataFrame();\n",
    "df['ratio'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=1, dataset='all', op='join')['RATIO'])\n",
    "df['t=1'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=1, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=4'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=4, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=16'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=16, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=32'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=32, dataset='all', op='join')['PGM_REL'])\n",
    "print(df.to_latex(index=False))\n",
    "\n",
    "df = pd.DataFrame();\n",
    "df['ratio'] = (compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['RATIO'])\n",
    "df['t=1'] = (compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=4'] = (compare_btree_pgm_duration(epsilon=2048, thread=4, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=16'] = (compare_btree_pgm_duration(epsilon=2048, thread=16, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=32'] = (compare_btree_pgm_duration(epsilon=2048, thread=32, dataset='all', op='merge')['PGM_REL'])\n",
    "print(df.to_latex(index=False))\n",
    "\n",
    "df = pd.DataFrame();\n",
    "df['ratio'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=1, dataset='all', op='merge')['RATIO'])\n",
    "df['t=1'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=1, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=4'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=4, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=16'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=16, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=32'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=32, dataset='all', op='merge')['PGM_REL'])\n",
    "print(df.to_latex(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = compare_btree_pgm_duration\n",
    "df = []\n",
    "df.append({'epsilon': 256, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='join')['PGM_REL'].mean()})\n",
    "df.append({'epsilon': 1024, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=1024, thread=1, dataset='all', op='join')['PGM_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='join')['PGM_REL'].mean()})\n",
    "\n",
    "df.append({'epsilon': 256, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='join')['BTREE_REL'].mean()})\n",
    "df.append({'epsilon': 1024, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=1024, thread=1, dataset='all', op='join')['BTREE_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='join')['BTREE_REL'].mean()})\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print(df.pivot(index='epsilon', columns='index', values='value').to_latex())\n",
    "\n",
    "f = compare_btree_pgm_duration\n",
    "df = []\n",
    "df.append({'epsilon': 256, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='merge')['PGM_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['PGM_REL'].mean()})\n",
    "\n",
    "df.append({'epsilon': 256, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='merge')['BTREE_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['BTREE_REL'].mean()})\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print(df.pivot(index='epsilon', columns='index', values='value').to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = compare_btree_pgm_duration\n",
    "df = []\n",
    "\n",
    "df.append({'epsilon': 2048, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['PGM_REL'].mean()})\n",
    "\n",
    "df.append({'epsilon': 512, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=512, thread=1, dataset='all', op='merge')['PGM_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['BTREE_REL'].mean()})\n",
    "df.append({'epsilon': 256, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='merge')['BTREE_REL'].mean()})\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print(df.pivot(index='epsilon', columns='index', values='value').to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
