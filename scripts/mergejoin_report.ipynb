{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['command', 'run', 'dataset', 'op', 'input_size', 'result.checksum',\n",
      "       'result.duration_ns', 'result.duration_sec', 'result.inner_disk_fetch',\n",
      "       'result.inner_disk_fetch_size', 'result.inner_total_bytes_fetched',\n",
      "       'result.outer_disk_fetch', 'result.outer_disk_fetch_size',\n",
      "       'result.outer_total_bytes_fetched', 'spec.algo', 'spec.algo_name',\n",
      "       'spec.check_checksum', 'spec.common_key',\n",
      "       'spec.index.leaf_size_in_pages', 'spec.index.search', 'spec.index.type',\n",
      "       'spec.inner_table', 'spec.key_size', 'spec.key_type',\n",
      "       'spec.load_sstable_in_mem', 'spec.name', 'spec.num_threads',\n",
      "       'spec.outer_table', 'spec.result_path', 'spec.value_size',\n",
      "       'spec.write_result_to_disk'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "import json;\n",
    "import builtins\n",
    "import pandas as pd;\n",
    "import duckdb\n",
    "\n",
    "dir = '/home/chesetti/Repos/learned_merge_cleanup/sponge'\n",
    "op = ['join', 'merge']\n",
    "#datasets = ['fb', 'wiki', 'uniform_dense', 'uniform_sparse', 'normal', 'lognormal', 'osm', 'books']\n",
    "#threads = [\"1\", \"4\", \"16\", \"32\"]\n",
    "datasets = ['str']\n",
    "threads = [\"1\", \"4\", \"8\"]\n",
    "for op in op:\n",
    "    for dataset in datasets:\n",
    "        for thread in threads:\n",
    "            testdir = os.path.join(dir, \"_\".join([op, dataset, thread]), \"outputs\", \"results\")\n",
    "            if (not os.path.exists(testdir)):\n",
    "                continue\n",
    "            rundirs = os.listdir(testdir)\n",
    "            for rundir in rundirs:\n",
    "                for test_result_file in os.listdir(os.path.join(testdir, rundir)):\n",
    "                    json_file = builtins.open(os.path.join(testdir, rundir, test_result_file))\n",
    "                    test_result = json.load(json_file)\n",
    "                    test_result['run'] = rundir\n",
    "                    test_result['dataset'] = dataset\n",
    "                    test_result['op'] = op\n",
    "                    if dataset == 'osm' or dataset == 'books':\n",
    "                        test_result['input_size'] = 800_000_000 \n",
    "                    elif dataset == 'str':\n",
    "                        test_result['input_size'] = 100_000_000\n",
    "                    else:\n",
    "                        test_result['input_size'] = 200_000_000 \n",
    "                    test_results.append(test_result)\n",
    "                    json_file.close()\n",
    "test_dataframe = pd.json_normalize(test_results)\n",
    "print(test_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               command  run dataset    op  \\\n",
      "3    numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "4    numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "5    numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "8    numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "10   numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "..                                                 ...  ...     ...   ...   \n",
      "703  numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "704  numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "707  numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "709  numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "711  numactl -N 1 -m 1 sponge/build/benchmark_runne...  run     str  join   \n",
      "\n",
      "      input_size  result.checksum  result.duration_ns  result.duration_sec  \\\n",
      "3    100000000.0              0.0        1.665465e+10            16.654654   \n",
      "4    100000000.0              0.0        1.812751e+10            18.127506   \n",
      "5    100000000.0              0.0        1.777915e+10            17.779150   \n",
      "8    100000000.0              0.0        7.909055e+09             7.909055   \n",
      "10   100000000.0              0.0        1.663021e+10            16.630206   \n",
      "..           ...              ...                 ...                  ...   \n",
      "703  100000000.0              0.0        4.577696e+08             0.457770   \n",
      "704  100000000.0              0.0        3.065250e+08             0.306525   \n",
      "707  100000000.0              0.0        4.160529e+08             0.416053   \n",
      "709  100000000.0              0.0        4.297974e+08             0.429797   \n",
      "711  100000000.0              0.0        2.793827e+08             0.279383   \n",
      "\n",
      "     result.inner_disk_fetch  result.inner_disk_fetch_size  ...  \\\n",
      "3                    48829.0                       32768.0  ...   \n",
      "4                   195313.0                        8192.0  ...   \n",
      "5                   195313.0                        8192.0  ...   \n",
      "8                    24415.0                       65536.0  ...   \n",
      "10                   48829.0                       32768.0  ...   \n",
      "..                       ...                           ...  ...   \n",
      "703                 195311.0                        8192.0  ...   \n",
      "704                  24422.0                       65536.0  ...   \n",
      "707                 194211.0                        8192.0  ...   \n",
      "709                  48836.0                       32768.0  ...   \n",
      "711                 194211.0                        8192.0  ...   \n",
      "\n",
      "     spec.num_threads                   spec.outer_table  \\\n",
      "3                 1.0    sponge/join_str_1/inputs/input5   \n",
      "4                 1.0    sponge/join_str_1/inputs/input5   \n",
      "5                 1.0    sponge/join_str_1/inputs/input5   \n",
      "8                 1.0   sponge/join_str_1/inputs/input10   \n",
      "10                1.0    sponge/join_str_1/inputs/input5   \n",
      "..                ...                                ...   \n",
      "703               8.0   sponge/join_str_8/inputs/input50   \n",
      "704               8.0  sponge/join_str_8/inputs/input100   \n",
      "707               8.0  sponge/join_str_8/inputs/input100   \n",
      "709               8.0   sponge/join_str_8/inputs/input50   \n",
      "711               8.0  sponge/join_str_8/inputs/input100   \n",
      "\n",
      "                                      spec.result_path  spec.value_size  \\\n",
      "3    sponge/join_str_1/outputs/btree1024_run_0_ratio_5             16.0   \n",
      "4     sponge/join_str_1/outputs/btree256_run_0_ratio_5             16.0   \n",
      "5     sponge/join_str_1/outputs/btree256_run_1_ratio_5             16.0   \n",
      "8    sponge/join_str_1/outputs/btree2048_run_0_rati...             16.0   \n",
      "10   sponge/join_str_1/outputs/btree1024_run_1_ratio_5             16.0   \n",
      "..                                                 ...              ...   \n",
      "703  sponge/join_str_8/outputs/btree256_run_0_ratio_50             16.0   \n",
      "704  sponge/join_str_8/outputs/btree2048_run_0_rati...             16.0   \n",
      "707  sponge/join_str_8/outputs/btree256_run_0_ratio...             16.0   \n",
      "709  sponge/join_str_8/outputs/btree1024_run_0_rati...             16.0   \n",
      "711  sponge/join_str_8/outputs/btree256_run_1_ratio...             16.0   \n",
      "\n",
      "    spec.write_result_to_disk threads duration_sec  ratio       algo  \\\n",
      "3                        True     1.0    16.654654    5.0  btree1024   \n",
      "4                        True     1.0    18.127506    5.0   btree256   \n",
      "5                        True     1.0    17.779150    5.0   btree256   \n",
      "8                        True     1.0     7.909055   10.0  btree2048   \n",
      "10                       True     1.0    16.630206    5.0  btree1024   \n",
      "..                        ...     ...          ...    ...        ...   \n",
      "703                      True     8.0     0.457770   50.0   btree256   \n",
      "704                      True     8.0     0.306525  100.0  btree2048   \n",
      "707                      True     8.0     0.416053  100.0   btree256   \n",
      "709                      True     8.0     0.429797   50.0  btree1024   \n",
      "711                      True     8.0     0.279383  100.0   btree256   \n",
      "\n",
      "    inner_bytes_fetched  \n",
      "3          1.600029e+09  \n",
      "4          1.600004e+09  \n",
      "5          1.600004e+09  \n",
      "8          1.600061e+09  \n",
      "10         1.600029e+09  \n",
      "..                  ...  \n",
      "703        1.599988e+09  \n",
      "704        1.600520e+09  \n",
      "707        1.590977e+09  \n",
      "709        1.600258e+09  \n",
      "711        1.590977e+09  \n",
      "\n",
      "[180 rows x 36 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>input_size</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>threads</th>\n",
       "      <th>ratio</th>\n",
       "      <th>op</th>\n",
       "      <th>algo</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_type</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>inner_bytes_fetched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree1024</td>\n",
       "      <td>btree1024</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>1024</td>\n",
       "      <td>16.654654</td>\n",
       "      <td>1.600029e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree256</td>\n",
       "      <td>btree256</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>256</td>\n",
       "      <td>18.127506</td>\n",
       "      <td>1.600004e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree256</td>\n",
       "      <td>btree256</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>256</td>\n",
       "      <td>17.779150</td>\n",
       "      <td>1.600004e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree2048</td>\n",
       "      <td>btree2048</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>2048</td>\n",
       "      <td>7.909055</td>\n",
       "      <td>1.600061e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree1024</td>\n",
       "      <td>btree1024</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>1024</td>\n",
       "      <td>16.630206</td>\n",
       "      <td>1.600029e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree256</td>\n",
       "      <td>btree256</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>256</td>\n",
       "      <td>0.457770</td>\n",
       "      <td>1.599988e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree2048</td>\n",
       "      <td>btree2048</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.306525</td>\n",
       "      <td>1.600520e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree256</td>\n",
       "      <td>btree256</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>256</td>\n",
       "      <td>0.416053</td>\n",
       "      <td>1.590977e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree1024</td>\n",
       "      <td>btree1024</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.429797</td>\n",
       "      <td>1.600258e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>str</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>SYNTHETIC</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>join</td>\n",
       "      <td>btree256</td>\n",
       "      <td>btree256</td>\n",
       "      <td>BTREE</td>\n",
       "      <td>256</td>\n",
       "      <td>0.279383</td>\n",
       "      <td>1.590977e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset   input_size dataset_type  threads  ratio    op       algo  \\\n",
       "3       str  100000000.0    SYNTHETIC      1.0    5.0  join  btree1024   \n",
       "4       str  100000000.0    SYNTHETIC      1.0    5.0  join   btree256   \n",
       "5       str  100000000.0    SYNTHETIC      1.0    5.0  join   btree256   \n",
       "8       str  100000000.0    SYNTHETIC      1.0   10.0  join  btree2048   \n",
       "10      str  100000000.0    SYNTHETIC      1.0    5.0  join  btree1024   \n",
       "..      ...          ...          ...      ...    ...   ...        ...   \n",
       "703     str  100000000.0    SYNTHETIC      8.0   50.0  join   btree256   \n",
       "704     str  100000000.0    SYNTHETIC      8.0  100.0  join  btree2048   \n",
       "707     str  100000000.0    SYNTHETIC      8.0  100.0  join   btree256   \n",
       "709     str  100000000.0    SYNTHETIC      8.0   50.0  join  btree1024   \n",
       "711     str  100000000.0    SYNTHETIC      8.0  100.0  join   btree256   \n",
       "\n",
       "    index_name index_type  epsilon  duration_sec  inner_bytes_fetched  \n",
       "3    btree1024      BTREE     1024     16.654654         1.600029e+09  \n",
       "4     btree256      BTREE      256     18.127506         1.600004e+09  \n",
       "5     btree256      BTREE      256     17.779150         1.600004e+09  \n",
       "8    btree2048      BTREE     2048      7.909055         1.600061e+09  \n",
       "10   btree1024      BTREE     1024     16.630206         1.600029e+09  \n",
       "..         ...        ...      ...           ...                  ...  \n",
       "703   btree256      BTREE      256      0.457770         1.599988e+09  \n",
       "704  btree2048      BTREE     2048      0.306525         1.600520e+09  \n",
       "707   btree256      BTREE      256      0.416053         1.590977e+09  \n",
       "709  btree1024      BTREE     1024      0.429797         1.600258e+09  \n",
       "711   btree256      BTREE      256      0.279383         1.590977e+09  \n",
       "\n",
       "[180 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = {\n",
    "    \"pgm256\": 256,\n",
    "    \"pgm1024\": 1024,\n",
    "    \"pgm2048\": 2048,\n",
    "    \"btree256\": 256,\n",
    "    \"btree512\": 512,\n",
    "    \"btree1024\": 1024,\n",
    "    \"btree1048\": 1024,\n",
    "    \"btree2048\": 2048,\n",
    "    \"hashjoin\": 0,\n",
    "    \"btree\": 0,\n",
    "    \"sj\": 0,\n",
    "    \"sj2\": 0,\n",
    "    \"standard_merge\": 0\n",
    "};\n",
    "indexType = {\n",
    "    \"pgm64\": \"PGM\",\n",
    "    \"pgm128\": \"PGM\",\n",
    "    \"pgm256\": \"PGM\",\n",
    "    \"pgm512\": \"PGM\",\n",
    "    \"pgm1024\": \"PGM\",\n",
    "    \"pgm2048\": \"PGM\",\n",
    "    \"btree256\": \"BTREE\",\n",
    "    \"btree512\": \"BTREE\",\n",
    "    \"btree1024\": \"BTREE\",\n",
    "    \"btree1048\": \"BTREE\",\n",
    "    \"btree2048\": \"BTREE\",\n",
    "    \"hashjoin\": \"NA\",\n",
    "    \"btree\": 0,\n",
    "    \"sj\": \"SJ\",\n",
    "    \"sj2\": \"NA\",\n",
    "    \"standard_merge\": \"SM\"\n",
    "};\n",
    "dataset_type = {\n",
    "    \"fb\": \"REAL\",\n",
    "    \"wiki\": \"REAL\",\n",
    "    \"osm\": \"REAL\",\n",
    "    \"books\": \"REAL\",\n",
    "    \"uniform_dense\": \"SYNTHETIC\",\n",
    "    \"uniform_sparse\": \"SYNTHETIC\",\n",
    "    \"normal\": \"SYNTHETIC\",\n",
    "    \"lognormal\": \"SYNTHETIC\",\n",
    "    \"str\": \"SYNTHETIC\"\n",
    "};\n",
    "dataset_display = {\n",
    "    \"fb\": \"fb\",\n",
    "    \"wiki\": \"wiki\",\n",
    "    \"osm\": \"osm\",\n",
    "    \"books\": \"books\",\n",
    "    \"uniform_dense\": \"udense\",\n",
    "    \"uniform_sparse\": \"usparse\",\n",
    "    \"normal\": \"normal\",\n",
    "    \"lognormal\": \"lognormal\",\n",
    "    \"str\": \"16 Byte Strings\"\n",
    "};\n",
    "dataset_order = {\n",
    "    \"fb\": 0,\n",
    "    \"wiki\": 1,\n",
    "    \"osm\": 2,\n",
    "    \"books\": 3,\n",
    "    \"uniform_dense\": 4,\n",
    "    \"uniform_sparse\": 5,\n",
    "    \"normal\": 6,\n",
    "    \"lognormal\": 7,\n",
    "};\n",
    "\n",
    "test_dataframe[\"threads\"] = test_dataframe[\"spec.num_threads\"]\n",
    "test_dataframe[\"duration_sec\"] = test_dataframe[\"result.duration_ns\"] / (1000000000)\n",
    "test_dataframe[\"ratio\"] = test_dataframe[\"spec.common_key\"]\n",
    "test_dataframe[\"algo\"] = test_dataframe[\"spec.algo_name\"]\n",
    "test_dataframe[\"inner_bytes_fetched\"] = test_dataframe[\"result.inner_total_bytes_fetched\"]\n",
    "test_dataframe[\"epsilon\"] = test_dataframe[\"spec.algo_name\"].map(lambda x: epsilon[str(x).lower()])\n",
    "test_dataframe[\"index_type\"] = test_dataframe[\"spec.algo_name\"].map(lambda x: indexType[str(x).lower()])\n",
    "test_dataframe[\"index_name\"] = test_dataframe[\"spec.algo_name\"]\n",
    "test_dataframe[\"dataset_type\"] = test_dataframe[\"dataset\"].map(lambda x: dataset_type[str(x).lower()])\n",
    "\n",
    "results = test_dataframe[[\"dataset\", \"input_size\", \"dataset_type\", \"threads\", \"ratio\", \"op\", \"algo\", \"index_name\", \"index_type\", \"epsilon\", \"duration_sec\", \"inner_bytes_fetched\"]]\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┬─────────┬─────────┬────────────┬────────────────────┐\n",
      "│ ratio  │ epsilon │   op    │ index_type │         v          │\n",
      "│ double │  int64  │ varchar │  varchar   │       double       │\n",
      "├────────┼─────────┼─────────┼────────────┼────────────────────┤\n",
      "│    1.0 │     256 │ join    │ BTREE      │ 107.32343088050001 │\n",
      "│    1.0 │    1024 │ join    │ BTREE      │      98.9206466565 │\n",
      "│    1.0 │    2048 │ join    │ BTREE      │      83.0556956555 │\n",
      "│    5.0 │     256 │ join    │ BTREE      │       17.953327884 │\n",
      "│    5.0 │    1024 │ join    │ BTREE      │        16.64242977 │\n",
      "│    5.0 │    2048 │ join    │ BTREE      │ 14.105155210500001 │\n",
      "│   10.0 │     256 │ join    │ BTREE      │      10.0505334765 │\n",
      "│   10.0 │    1024 │ join    │ BTREE      │  9.321297672499998 │\n",
      "│   10.0 │    2048 │ join    │ BTREE      │        7.921087028 │\n",
      "│   50.0 │     256 │ join    │ BTREE      │       2.4161692415 │\n",
      "│   50.0 │    1024 │ join    │ BTREE      │        2.245783418 │\n",
      "│   50.0 │    2048 │ join    │ BTREE      │        1.923837786 │\n",
      "│  100.0 │     256 │ join    │ BTREE      │       1.3915019225 │\n",
      "│  100.0 │    1024 │ join    │ BTREE      │       1.2739371755 │\n",
      "│  100.0 │    2048 │ join    │ BTREE      │ 1.4354972849999998 │\n",
      "├────────┴─────────┴─────────┴────────────┴────────────────────┤\n",
      "│ 15 rows                                            5 columns │\n",
      "└──────────────────────────────────────────────────────────────┘\n",
      "\n",
      "┌────────┬───────────────────┬────────────────────┬────────────────────┐\n",
      "│ ratio  │    BTREE_1024     │     BTREE_2048     │     BTREE_256      │\n",
      "│ double │      double       │       double       │       double       │\n",
      "├────────┼───────────────────┼────────────────────┼────────────────────┤\n",
      "│    1.0 │     98.9206466565 │      83.0556956555 │ 107.32343088050001 │\n",
      "│    5.0 │       16.64242977 │ 14.105155210500001 │       17.953327884 │\n",
      "│   10.0 │ 9.321297672499998 │        7.921087028 │      10.0505334765 │\n",
      "│   50.0 │       2.245783418 │        1.923837786 │       2.4161692415 │\n",
      "│  100.0 │      1.2739371755 │ 1.4354972849999998 │       1.3915019225 │\n",
      "└────────┴───────────────────┴────────────────────┴────────────────────┘\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['SJ_0', 'PGM_256', 'PGM_2048'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m p \u001b[39m=\u001b[39m (duckdb\u001b[39m.\u001b[39msql(\u001b[39m\"\u001b[39m\u001b[39mPIVOT rows ON index_type,epsilon USING avg(v) GROUP BY ratio ORDER BY RATIO\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(p)\n\u001b[0;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m(p\u001b[39m.\u001b[39;49mdf()[[\u001b[39m'\u001b[39;49m\u001b[39mratio\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSJ_0\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mBTREE_256\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mBTREE_2048\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mPGM_256\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mPGM_2048\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mto_latex(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, float_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['SJ_0', 'PGM_256', 'PGM_2048'] not in index\""
     ]
    }
   ],
   "source": [
    "# Average results by time.\n",
    "input_size = 100_000_000\n",
    "rows = duckdb.sql(\n",
    "    \" SELECT ratio, epsilon, op, index_type, AVG(duration_sec) as v FROM results \"\n",
    "    f\" WHERE threads = 1 AND input_size={input_size} AND op='join' AND index_type!='NA'\"\n",
    "    \" GROUP BY ratio, threads, op, input_size, index_type, epsilon\"\n",
    "    \" ORDER BY ratio, threads, epsilon\"\n",
    ")\n",
    "print(rows)\n",
    "p = (duckdb.sql(\"PIVOT rows ON index_type,epsilon USING avg(v) GROUP BY ratio ORDER BY RATIO\"))\n",
    "print(p)\n",
    "print(p.df()[['ratio', 'SJ_0', 'BTREE_256', 'BTREE_2048', 'PGM_256', 'PGM_2048']].to_latex(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = duckdb.sql(\n",
    "    \" SELECT ratio, threads, epsilon, op, index_name, AVG(duration_sec) as v FROM results \"\n",
    "    \" WHERE (ratio=10 or ratio=50 or ratio=100) AND input_size=200000000 AND op='join' AND index_type!='NA'\"\n",
    "    \" AND (index_name='sj' OR epsilon=2048)\"\n",
    "    \" GROUP BY ratio, threads, op, input_size, index_name, epsilon\"\n",
    "    \" ORDER BY ratio, threads, epsilon\"\n",
    ")\n",
    "rows\n",
    "print(duckdb.sql(\"PIVOT rows ON index_name USING AVG(v) GROUP BY threads,ratio ORDER BY threads,ratio\").df().to_latex(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────┐\n",
      "│ ratio  │\n",
      "│ double │\n",
      "├────────┤\n",
      "│ 0 rows │\n",
      "└────────┘\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['SM_0', 'BTREE_256', 'BTREE_2048', 'PGM_256', 'PGM_2048'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m p \u001b[39m=\u001b[39m (duckdb\u001b[39m.\u001b[39msql(\u001b[39m\"\u001b[39m\u001b[39mPIVOT rows ON index_type,epsilon USING avg(v) GROUP BY ratio ORDER BY RATIO\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(p)\n\u001b[0;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(p\u001b[39m.\u001b[39;49mdf()[[\u001b[39m'\u001b[39;49m\u001b[39mratio\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSM_0\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mBTREE_256\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mBTREE_2048\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mPGM_256\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mPGM_2048\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mto_latex(index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, float_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['SM_0', 'BTREE_256', 'BTREE_2048', 'PGM_256', 'PGM_2048'] not in index\""
     ]
    }
   ],
   "source": [
    "rows = duckdb.sql(\n",
    "    \" SELECT ratio, epsilon, op, index_type, AVG(duration_sec) as v FROM results \"\n",
    "    \" WHERE threads = 1 AND input_size=200000000 AND op='merge' AND index_type!='NA'\"\n",
    "    \" GROUP BY ratio, threads, op, input_size, index_type, epsilon\"\n",
    "    \" ORDER BY ratio, threads, epsilon\"\n",
    ")\n",
    "p = (duckdb.sql(\"PIVOT rows ON index_type,epsilon USING avg(v) GROUP BY ratio ORDER BY RATIO\"))\n",
    "print(p)\n",
    "print(p.df()[['ratio', 'SM_0', 'BTREE_256', 'BTREE_2048', 'PGM_256', 'PGM_2048']].to_latex(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      "threads & ratio & btree2048 & pgm2048 \\\\\n",
      "\\midrule\n",
      "1 & 10 & 6.245 & 4.826 \\\\\n",
      "1 & 50 & 3.518 & 3.243 \\\\\n",
      "1 & 100 & 3.117 & 2.979 \\\\\n",
      "4 & 10 & 2.702 & 2.647 \\\\\n",
      "4 & 50 & 2.500 & 2.641 \\\\\n",
      "4 & 100 & 2.532 & 2.436 \\\\\n",
      "16 & 10 & 2.722 & 2.705 \\\\\n",
      "16 & 50 & 2.550 & 2.514 \\\\\n",
      "16 & 100 & 2.509 & 2.491 \\\\\n",
      "32 & 10 & 2.900 & 2.949 \\\\\n",
      "32 & 50 & 2.703 & 2.767 \\\\\n",
      "32 & 100 & 2.749 & 2.730 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = duckdb.sql(\n",
    "    \" SELECT ratio, threads, epsilon, op, index_name, AVG(duration_sec) as v FROM results \"\n",
    "    \" WHERE (ratio=10 or ratio=50 or ratio=100) AND input_size=200000000 AND op='merge' AND index_type!='NA'\"\n",
    "    \" AND (index_name='standard_merge' OR epsilon=2048)\"\n",
    "    \" GROUP BY ratio, threads, op, input_size, index_name, epsilon\"\n",
    "    \" ORDER BY ratio, threads, epsilon\"\n",
    ")\n",
    "rows\n",
    "print(duckdb.sql(\"PIVOT rows ON index_name USING AVG(v) GROUP BY threads,ratio ORDER BY threads,ratio\").df().to_latex(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_threads(op, ratio):\n",
    "    rows = duckdb.sql(\n",
    "        \" SELECT ratio,index_name,threads, MEDIAN(duration) as v\"\n",
    "        f\" FROM results where op='{op}' AND ratio={ratio}  AND index_type!='NA'\"\n",
    "        \" GROUP BY dataset, ratio, index_name, threads \"\n",
    "        \" ORDER BY Threads\")\n",
    "    return duckdb.sql('PIVOT rows ON index_name USING MEDIAN(v)')\n",
    "ratios = [10, 50, 100]\n",
    "for ratio in ratios:\n",
    "    for op in ['join', 'merge']:\n",
    "        group_by_threads(op, ratio).df().to_csv('_'.join([op, str(ratio), 'threadStudy.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGM Index Memory Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_btree_pgm_memory(epsilon, thread, dataset_type):\n",
    "        where = f\"WHERE threads={thread} AND epsilon={epsilon} AND ratio=10 \"\n",
    "        if dataset_type != \"all\":\n",
    "                where = where + f\" AND dataset_type='{dataset_type}' \"\n",
    "        query = (\"SELECT ratio, threads, algo, index_type, dataset, dataset_type,\"\n",
    "                \"epsilon, MEAN(index_memory) as memory_mean, FROM results \" \n",
    "                + where +\n",
    "                \"GROUP BY (ratio, threads, algo, index_type, epsilon, dataset, dataset_type) \"\n",
    "                \"ORDER BY ratio\")\n",
    "        subresult = duckdb.sql(query)\n",
    "        df = duckdb.sql(\"PIVOT subresult ON index_type USING MEAN(memory_mean) GROUP BY ratio,dataset\").df()\n",
    "        df['REL'] = (df['PGM']) / df['BTREE']\n",
    "        return df\n",
    "\n",
    "def compare_btree_pgm_build_duration(epsilon, thread, dataset_type):\n",
    "        where = f\"WHERE threads={thread} AND epsilon={epsilon} AND ratio=10 \"\n",
    "        if dataset_type != \"all\":\n",
    "                where = where + f\" AND dataset_type='{dataset_type}' \"\n",
    "        query = (\"SELECT ratio, threads, algo, index_type, dataset, dataset_type,\"\n",
    "                \"epsilon, MEAN(index_build_duration) as index_build_duration, FROM results \" \n",
    "                + where +\n",
    "                \"GROUP BY (ratio, threads, algo, index_type, epsilon, dataset, dataset_type) \"\n",
    "                \"ORDER BY ratio\")\n",
    "        subresult = duckdb.sql(query)\n",
    "        df = duckdb.sql(\"PIVOT subresult ON index_type USING MEAN(index_build_duration) GROUP BY ratio,dataset\").df()\n",
    "        df['REL'] = (df['PGM']) / df['BTREE']\n",
    "        return df\n",
    "dict = []\n",
    "dict.append({\n",
    "        'epsilon':256, \n",
    "        'ALL': compare_btree_pgm_memory(epsilon=256, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_memory(epsilon=256, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_memory(epsilon=256, thread=1, dataset_type='SYNTHETIC')['REL'].mean(),\n",
    "        'ACTUAL': compare_btree_pgm_memory(epsilon=256, thread=1, dataset_type='all')['PGM'].mean(),\n",
    "        })\n",
    "dict.append({\n",
    "        'epsilon':1024, \n",
    "        'ALL': compare_btree_pgm_memory(epsilon=1024, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_memory(epsilon=1024, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_memory(epsilon=1024, thread=1, dataset_type='SYNTHETIC')['REL'].mean(),\n",
    "        'ACTUAL': compare_btree_pgm_memory(epsilon=1024, thread=1, dataset_type='all')['PGM'].mean(),\n",
    "        })\n",
    "dict.append({\n",
    "        'epsilon': 2048, \n",
    "        'ALL': compare_btree_pgm_memory(epsilon=2048, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_memory(epsilon=2048, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_memory(epsilon=2048, thread=1, dataset_type='SYNTHETIC')['REL'].mean(),\n",
    "        'ACTUAL': compare_btree_pgm_memory(epsilon=2048, thread=1, dataset_type='all')['PGM'].mean(),\n",
    "        })\n",
    "\n",
    "print(pd.DataFrame(dict).to_latex(index=False))\n",
    "\n",
    "dict = []\n",
    "dict.append({\n",
    "        'epsilon':256, \n",
    "        'ALL': compare_btree_pgm_build_duration(epsilon=256, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_build_duration(epsilon=256, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_build_duration(epsilon=256, thread=1, dataset_type='SYNTHETIC')['REL'].mean()\n",
    "        })\n",
    "dict.append({\n",
    "        'epsilon':1024, \n",
    "        'ALL': compare_btree_pgm_build_duration(epsilon=1024, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_build_duration(epsilon=1024, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_build_duration(epsilon=1024, thread=1, dataset_type='SYNTHETIC')['REL'].mean()\n",
    "        })\n",
    "dict.append({\n",
    "        'epsilon': 2048, \n",
    "        'ALL': compare_btree_pgm_build_duration(epsilon=2048, thread=1, dataset_type='all')['REL'].mean(),\n",
    "        'REAL': compare_btree_pgm_build_duration(epsilon=2048, thread=1, dataset_type='REAL')['REL'].mean(),\n",
    "        'SYNTHETIC': compare_btree_pgm_build_duration(epsilon=2048, thread=1, dataset_type='SYNTHETIC')['REL'].mean()\n",
    "        })\n",
    "print(pd.DataFrame(dict).to_latex(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGM vs TREE SJ same epsilon (Duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_btree_pgm_duration(epsilon, thread, dataset, op):\n",
    "        where = f\"WHERE threads={thread} AND op='{op}' AND (epsilon={epsilon} OR algo='sj' OR algo='standard_merge')\"\n",
    "        if dataset != \"all\":\n",
    "                where = where + f\"AND dataset='{dataset}'\"\n",
    "        query = (\"SELECT ratio, threads, algo, index_type,\"\n",
    "                \"epsilon, MEDIAN(duration) as duration_mean, FROM results \" \n",
    "                + where +\n",
    "                \"GROUP BY (ratio, threads, algo, index_type, epsilon) \"\n",
    "                \"ORDER BY ratio\")\n",
    "        subresult = duckdb.sql(query)\n",
    "        print(subresult)\n",
    "        df = duckdb.sql(\"PIVOT subresult ON index_type USING sum(duration_mean) GROUP BY ratio\").df()\n",
    "        print(df)\n",
    "        baseline = 'SJ' if op == 'join' else 'SM'\n",
    "        df['RATIO'] = df['ratio']\n",
    "        if 'PGM' in df.columns:\n",
    "                df['PGM_REL'] = (df['PGM']/ df[baseline])\n",
    "        if 'BTREE' in df.columns:\n",
    "                df['BTREE_REL'] = (df['BTREE']/ df[baseline])\n",
    "        return df\n",
    "\n",
    "def compare_pgm_bytes_fetched(epsilon, thread, dataset, op):\n",
    "        where = f\"WHERE threads={thread} AND op='{op}' AND (epsilon={epsilon} OR algo='sj' OR algo='standard_merge')\"\n",
    "        if dataset != \"all\":\n",
    "                where = where + f\"AND dataset='{dataset}'\"\n",
    "        query = (\"SELECT ratio, threads, algo, index_type,\"\n",
    "                \"epsilon, MEDIAN(inner_bytes_fetched) as median, FROM results \" \n",
    "                + where +\n",
    "                \"GROUP BY (ratio, threads, algo, index_type, epsilon) \"\n",
    "                \"ORDER BY ratio\")\n",
    "        subresult = duckdb.sql(query)\n",
    "        df = duckdb.sql(\"PIVOT subresult ON index_type USING AVG(median) GROUP BY ratio\").df()\n",
    "        baseline = 'SJ' if op == 'join' else 'SM'\n",
    "        df['RATIO'] = df['ratio']\n",
    "        df['BTREE_REL'] = (df['BTREE']/ df[baseline])\n",
    "        df['PGM_REL'] = (df['PGM']/ df[baseline])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame();\n",
    "df['ratio'] = (compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='join')['RATIO'])\n",
    "df['t=1'] = (compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=4'] = (compare_btree_pgm_duration(epsilon=2048, thread=4, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=16'] = (compare_btree_pgm_duration(epsilon=2048, thread=16, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=32'] = (compare_btree_pgm_duration(epsilon=2048, thread=32, dataset='all', op='join')['PGM_REL'])\n",
    "print(df.to_latex(index=False))\n",
    "\n",
    "df = pd.DataFrame();\n",
    "df['ratio'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=1, dataset='all', op='join')['RATIO'])\n",
    "df['t=1'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=1, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=4'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=4, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=16'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=16, dataset='all', op='join')['PGM_REL'])\n",
    "df['t=32'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=32, dataset='all', op='join')['PGM_REL'])\n",
    "print(df.to_latex(index=False))\n",
    "\n",
    "df = pd.DataFrame();\n",
    "df['ratio'] = (compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['RATIO'])\n",
    "df['t=1'] = (compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=4'] = (compare_btree_pgm_duration(epsilon=2048, thread=4, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=16'] = (compare_btree_pgm_duration(epsilon=2048, thread=16, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=32'] = (compare_btree_pgm_duration(epsilon=2048, thread=32, dataset='all', op='merge')['PGM_REL'])\n",
    "print(df.to_latex(index=False))\n",
    "\n",
    "df = pd.DataFrame();\n",
    "df['ratio'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=1, dataset='all', op='merge')['RATIO'])\n",
    "df['t=1'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=1, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=4'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=4, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=16'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=16, dataset='all', op='merge')['PGM_REL'])\n",
    "df['t=32'] = (compare_pgm_bytes_fetched(epsilon=2048, thread=32, dataset='all', op='merge')['PGM_REL'])\n",
    "print(df.to_latex(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = compare_btree_pgm_duration\n",
    "df = []\n",
    "df.append({'epsilon': 256, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='join')['PGM_REL'].mean()})\n",
    "df.append({'epsilon': 1024, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=1024, thread=1, dataset='all', op='join')['PGM_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='join')['PGM_REL'].mean()})\n",
    "\n",
    "df.append({'epsilon': 256, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='join')['BTREE_REL'].mean()})\n",
    "df.append({'epsilon': 1024, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=1024, thread=1, dataset='all', op='join')['BTREE_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='join')['BTREE_REL'].mean()})\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print(df.pivot(index='epsilon', columns='index', values='value').to_latex())\n",
    "\n",
    "f = compare_btree_pgm_duration\n",
    "df = []\n",
    "df.append({'epsilon': 256, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='merge')['PGM_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['PGM_REL'].mean()})\n",
    "\n",
    "df.append({'epsilon': 256, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='merge')['BTREE_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['BTREE_REL'].mean()})\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print(df.pivot(index='epsilon', columns='index', values='value').to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = compare_btree_pgm_duration\n",
    "df = []\n",
    "\n",
    "df.append({'epsilon': 2048, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['PGM_REL'].mean()})\n",
    "\n",
    "df.append({'epsilon': 512, 'index': 'PGM', 't': 1, 'value': compare_btree_pgm_duration(epsilon=512, thread=1, dataset='all', op='merge')['PGM_REL'].mean()})\n",
    "df.append({'epsilon': 2048, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=2048, thread=1, dataset='all', op='merge')['BTREE_REL'].mean()})\n",
    "df.append({'epsilon': 256, 'index': 'BTREE', 't': 1, 'value': compare_btree_pgm_duration(epsilon=256, thread=1, dataset='all', op='merge')['BTREE_REL'].mean()})\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print(df.pivot(index='epsilon', columns='index', values='value').to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
