{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/chesetti/Repos/learned_merge_cleanup/sponge/fb_merge-onelevel_1/outputs/results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[198], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m csv_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(test_dir, \u001b[39m'\u001b[39m\u001b[39mcsv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m os\u001b[39m.\u001b[39mmakedirs(csv_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m runs \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(results_dir, run) \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(results_dir)]\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(runs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/chesetti/Repos/learned_merge_cleanup/sponge/fb_merge-onelevel_1/outputs/results'"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "import json;\n",
    "import builtins\n",
    "import pandas as pd;\n",
    "\n",
    "dir = '/home/chesetti/Repos/learned_merge_cleanup/sponge'\n",
    "testcase = 'fb_join-onelevel_1'\n",
    "test_dir = os.path.join(dir, testcase)\n",
    "results_dir = os.path.join(test_dir, 'outputs', 'results')\n",
    "csv_dir = os.path.join(test_dir, 'csv')\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "runs = [os.path.join(results_dir, run) for run in os.listdir(results_dir)]\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['command', 'run', 'result.checksum', 'result.duration_ns',\n",
      "       'result.duration_sec', 'result.inner_disk_fetch',\n",
      "       'result.inner_index_build_duration_ns', 'result.inner_index_size',\n",
      "       'result.outer_disk_fetch', 'spec.algo', 'spec.algo_name',\n",
      "       'spec.common_key', 'spec.index.search', 'spec.index.type',\n",
      "       'spec.inner_table', 'spec.key_size', 'spec.key_type',\n",
      "       'spec.load_sstable_in_mem', 'spec.name', 'spec.num_threads',\n",
      "       'spec.outer_table', 'spec.result_path', 'spec.value_size',\n",
      "       'spec.write_result_to_disk', 'spec.index.leaf_size_in_pages'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Walk all the json files and put them in a dataframe\n",
    "\n",
    "test_results = []\n",
    "for run in runs:\n",
    "    for test_result_file in os.listdir(run):\n",
    "        json_file = builtins.open(os.path.join(run, test_result_file))\n",
    "        test_result = json.load(json_file)\n",
    "        test_result['run'] = run\n",
    "        test_results.append(test_result)\n",
    "        json_file.close()\n",
    "test_dataframe = pd.json_normalize(test_results)\n",
    "print(test_dataframe.columns)\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec.algo_name       BTree    PGM1024     PGM256      PGM64  standard_merge\n",
      "spec.common_key                                                            \n",
      "1                606160089  366958773  373037464  377308888       285113650\n",
      "2                317003678  212197200  213604378  209402956       247252022\n",
      "3                252606097  159362202  156869322  156202667       208862321\n",
      "4                178062653  123901170  126693906  139224538       167555758\n",
      "5                152279125  109620721  116857813  125542114       179591942\n",
      "6                148263693  112560342  107039107  102140839       174632651\n",
      "7                123130904   94173019   99481311  103293318       170801862\n",
      "8                126574979   93564080   94215218   88969271       147882179\n",
      "9                105425032   89020925   87554369   84272262       145322552\n",
      "10                99510093   84620707   85804130   82344143       141392439\n"
     ]
    }
   ],
   "source": [
    "overall_duration = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.duration_ns', aggfunc='median')\n",
    "overall_duration.to_csv(os.path.join(csv_dir, 'duration_sec.csv'))\n",
    "print(overall_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          indexes  memory_bytes\n",
      "0           BTree       20592.0\n",
      "1         PGM1024         152.0\n",
      "2          PGM256        1032.0\n",
      "3           PGM64       13744.0\n",
      "4  standard_merge      161664.0\n"
     ]
    }
   ],
   "source": [
    "inner_index_size = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_index_size', aggfunc='median')\n",
    "data = {}\n",
    "data['indexes'] = []\n",
    "data['memory_bytes'] = []\n",
    "for index in inner_index_size:\n",
    "    data['indexes'].append(index)\n",
    "    data['memory_bytes'].append(inner_index_size[index].mean())\n",
    "inner_index_size = pd.DataFrame(data=data)\n",
    "inner_index_size.to_csv(os.path.join(csv_dir, 'inner_index_size.csv'))\n",
    "print(inner_index_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_index_build_duration = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_index_build_duration_ns', aggfunc='median')\n",
    "data = {}\n",
    "data['indexes'] = []\n",
    "data['build_duration'] = []\n",
    "for index in inner_index_build_duration:\n",
    "    data['indexes'].append(index)\n",
    "    data['build_duration'].append(inner_index_build_duration[index].mean())\n",
    "inner_index_build_duration = pd.DataFrame(data=data)\n",
    "inner_index_build_duration.to_csv(os.path.join(csv_dir, 'inner_index_build_duration_ns.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec.algo_name   BTree  PGM1024  PGM256  PGM64  standard_merge\n",
      "spec.common_key                                               \n",
      "1                 7774     7774    7774   7774            7774\n",
      "2                 7775     7775    7775   7775            7774\n",
      "3                 7775     7775    7775   7775            7774\n",
      "4                 7774     7774    7774   7774            7774\n",
      "5                 7774     7774    7774   7774            7774\n",
      "6                 7774     7774    7774   7774            7774\n",
      "7                 7774     7774    7774   7774            7774\n",
      "8                 7774     7774    7774   7774            7774\n",
      "9                 7774     7774    7774   7774            7774\n",
      "10                7774     7774    7774   7774            7774\n"
     ]
    }
   ],
   "source": [
    "inner_index_fetch = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_disk_fetch', aggfunc='median')\n",
    "print(inner_index_fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_key: 1 checksum: ['FB1325CD1EF6A662FDB62437963A8DD5'] OK\n",
      "common_key: 2 checksum: ['B546A407990E8FCAD0E4BAC58C5665D8'] OK\n",
      "common_key: 3 checksum: ['4FC3A19486DB5C190F9AD70876BDEDF8'] OK\n",
      "common_key: 4 checksum: ['851AEB57B15C646D1558BA702BDF7F63'] OK\n",
      "common_key: 5 checksum: ['055B1A29A1A05237AB91998CAB7A7CA6'] OK\n",
      "common_key: 6 checksum: ['DA06D0BB6A18417D754255F6D8A124AD'] OK\n",
      "common_key: 7 checksum: ['C1B3AD5394742782DCFA4C9CF924908D'] OK\n",
      "common_key: 8 checksum: ['671B084C9E572A8BEB928111959D1A98'] OK\n",
      "common_key: 9 checksum: ['9AC46D4F7E8FEDD804D7E6495D6C0155'] OK\n",
      "common_key: 10 checksum: ['3985DF0E03E87AFA419795428B2DFCBB'] OK\n",
      "Empty DataFrame\n",
      "Columns: [spec.common_key, spec.algo_name, result.checksum]\n",
      "Index: []\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "result_checksum = (test_dataframe[['spec.common_key', 'spec.algo_name', 'result.checksum']].sort_values(by=['spec.common_key', 'spec.algo_name'])) #.loc[test_dataframe['spec.common_key']=='10'])\n",
    "for common_key in sorted(test_dataframe['spec.common_key'].unique()):\n",
    "    checksums = result_checksum.loc[result_checksum['spec.common_key'] == common_key]\n",
    "    unique_checksums = checksums['result.checksum'].unique()\n",
    "    if (len(unique_checksums) == 1):\n",
    "        print(f\"common_key: {common_key} checksum: {unique_checksums} OK\")\n",
    "    else:\n",
    "        print(f\"common_key: {common_key} checksums don't match\")\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 40])\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 40]['result.checksum'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
