{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/chesetti/Repos/learned_merge_cleanup/sponge/merge_str_1/outputs/results/run']\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "import json;\n",
    "import builtins\n",
    "import pandas as pd;\n",
    "\n",
    "dir = '/home/chesetti/Repos/learned_merge_cleanup/sponge'\n",
    "testcase = 'merge_str_1'\n",
    "test_dir = os.path.join(dir, testcase)\n",
    "results_dir = os.path.join(test_dir, 'outputs', 'results')\n",
    "csv_dir = os.path.join(test_dir, 'csv')\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "runs = [os.path.join(results_dir, run) for run in os.listdir(results_dir)]\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['command', 'run', 'result.checksum', 'result.duration_ns',\n",
      "       'result.duration_sec', 'result.inner_disk_fetch',\n",
      "       'result.inner_disk_fetch_size', 'result.inner_total_bytes_fetched',\n",
      "       'result.outer_disk_fetch', 'result.outer_disk_fetch_size',\n",
      "       'result.outer_total_bytes_fetched', 'spec.algo', 'spec.algo_name',\n",
      "       'spec.common_key', 'spec.inner_table', 'spec.key_size', 'spec.key_type',\n",
      "       'spec.load_sstable_in_mem', 'spec.name', 'spec.num_threads',\n",
      "       'spec.outer_table', 'spec.result_path', 'spec.value_size',\n",
      "       'spec.write_result_to_disk', 'spec.index.search', 'spec.index.type',\n",
      "       'spec.index.leaf_size_in_pages'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Walk all the json files and put them in a dataframe\n",
    "\n",
    "test_results = []\n",
    "for run in runs:\n",
    "    for test_result_file in os.listdir(run):\n",
    "        json_file = builtins.open(os.path.join(run, test_result_file))\n",
    "        test_result = json.load(json_file)\n",
    "        test_result['run'] = run\n",
    "        test_results.append(test_result)\n",
    "        json_file.close()\n",
    "test_dataframe = pd.json_normalize(test_results)\n",
    "print(test_dataframe.columns)\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['btree1024', 'btree2048', 'btree256', 'pgm1024', 'pgm2048', 'pgm256',\n",
      "       'standard_merge'],\n",
      "      dtype='object', name='spec.algo_name')\n",
      "Index([1, 2, 5, 10, 50, 100], dtype='int64', name='spec.common_key')\n",
      "spec.algo_name   btree1024  btree2048   btree256    pgm1024    pgm2048  \\\n",
      "spec.common_key                                                          \n",
      "1                960167388  955038093  980318855  359586959  363311453   \n",
      "2                343314593  340871107  346632653  156174093  157599156   \n",
      "5                207834554  206903302  213274367  115256167  103712382   \n",
      "10               138185814  140222892  142090142   86991699   85005585   \n",
      "50                74698572   73028631   73702278   67271383   59670606   \n",
      "100               61650414   64470371   59812250   57955189   57230042   \n",
      "\n",
      "spec.algo_name      pgm256  standard_merge  \n",
      "spec.common_key                             \n",
      "1                381174969       160488433  \n",
      "2                162918097       107590799  \n",
      "5                113648030        95472509  \n",
      "10                88677012        88579827  \n",
      "50                61353900        81083082  \n",
      "100               58114922        79206393  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor column in throughput.columns:\\n    throughput[column] = (200_000_000/throughput.index) * (1000_000_000.0 / throughput[column])\\n    throughput[column +\"_sj-rel\"] = (throughput[column] - throughput[\"sj\"] / throughput[\"sj\"]) * 100.0\\nprint(throughput)\\noverall_duration[[\"btree2048\", \"btree1024\", \"btree256\", \"sj\"]].plot() \\noverall_duration[[\"pgm128\", \"pgm512\", \"pgm1024\", \"sj\"]].plot() \\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_duration = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.duration_ns', aggfunc='median')\n",
    "overall_duration.to_csv(os.path.join(csv_dir, 'duration_sec.csv'))\n",
    "print(overall_duration.columns)\n",
    "print(overall_duration.index)\n",
    "print(overall_duration)\n",
    "throughput = overall_duration\n",
    "'''\n",
    "for column in throughput.columns:\n",
    "    throughput[column] = (200_000_000/throughput.index) * (1000_000_000.0 / throughput[column])\n",
    "    throughput[column +\"_sj-rel\"] = (throughput[column] - throughput[\"sj\"] / throughput[\"sj\"]) * 100.0\n",
    "print(throughput)\n",
    "overall_duration[[\"btree2048\", \"btree1024\", \"btree256\", \"sj\"]].plot() \n",
    "overall_duration[[\"pgm128\", \"pgm512\", \"pgm1024\", \"sj\"]].plot() \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec.algo_name   btree1024  btree2048  btree256  pgm1024  pgm2048  pgm256  \\\n",
      "spec.common_key                                                             \n",
      "1                     7813       7813      7813     7813     7813    7813   \n",
      "2                     7813       7813      7813     7813     7813    7813   \n",
      "5                     7813       7813      7813     7813     7813    7813   \n",
      "10                    7813       7813      7813     7813     7813    7813   \n",
      "50                    7813       7813      7813     7813     7813    7813   \n",
      "100                   7813       7813      7813     7813     7813    7813   \n",
      "\n",
      "spec.algo_name   standard_merge  \n",
      "spec.common_key                  \n",
      "1                          7813  \n",
      "2                          7813  \n",
      "5                          7813  \n",
      "10                         7813  \n",
      "50                         7813  \n",
      "100                        7813  \n",
      "spec.algo_name   btree1024  btree2048  btree256   pgm1024   pgm2048    pgm256  \\\n",
      "spec.common_key                                                                 \n",
      "1                 32000000   32000000  32000000  32000000  32000000  32000000   \n",
      "2                 32000000   32000000  32000000  32000000  32000000  32000000   \n",
      "5                 32000000   32000000  32000000  32000000  32000000  32000000   \n",
      "10                32000000   32000000  32000000  32000000  32000000  32000000   \n",
      "50                32000000   32000000  32000000  32000000  32000000  32000000   \n",
      "100               32000000   32000000  32000000  32000000  32000000  32000000   \n",
      "\n",
      "spec.algo_name   standard_merge  \n",
      "spec.common_key                  \n",
      "1                      32000000  \n",
      "2                      32000000  \n",
      "5                      32000000  \n",
      "10                     32000000  \n",
      "50                     32000000  \n",
      "100                    32000000  \n",
      "spec.algo_name   btree1024  btree2048  btree256  pgm1024  pgm2048  pgm256  \\\n",
      "spec.common_key                                                             \n",
      "1                     4096       4096      4096     4096     4096    4096   \n",
      "2                     4096       4096      4096     4096     4096    4096   \n",
      "5                     4096       4096      4096     4096     4096    4096   \n",
      "10                    4096       4096      4096     4096     4096    4096   \n",
      "50                    4096       4096      4096     4096     4096    4096   \n",
      "100                   4096       4096      4096     4096     4096    4096   \n",
      "\n",
      "spec.algo_name   standard_merge  \n",
      "spec.common_key                  \n",
      "1                          4096  \n",
      "2                          4096  \n",
      "5                          4096  \n",
      "10                         4096  \n",
      "50                         4096  \n",
      "100                        4096  \n"
     ]
    }
   ],
   "source": [
    "inner_index_fetch = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_disk_fetch', aggfunc='median')\n",
    "inner_index_total_fetch = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_total_bytes_fetched', aggfunc='median')\n",
    "inner_index_fetch_size = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_disk_fetch_size', aggfunc='median')\n",
    "print(inner_index_fetch)\n",
    "print(inner_index_total_fetch)\n",
    "print(inner_index_fetch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_key: 1 checksum: [0] OK\n",
      "common_key: 2 checksum: [0] OK\n",
      "common_key: 5 checksum: [0] OK\n",
      "common_key: 10 checksum: [0] OK\n",
      "common_key: 50 checksum: [0] OK\n",
      "common_key: 100 checksum: [0] OK\n",
      "     spec.common_key  spec.algo_name  result.checksum\n",
      "74               100       btree1024                0\n",
      "93               100       btree1024                0\n",
      "115              100       btree1024                0\n",
      "4                100       btree2048                0\n",
      "40               100       btree2048                0\n",
      "104              100       btree2048                0\n",
      "110              100        btree256                0\n",
      "116              100        btree256                0\n",
      "117              100        btree256                0\n",
      "17               100         pgm1024                0\n",
      "72               100         pgm1024                0\n",
      "80               100         pgm1024                0\n",
      "46               100         pgm2048                0\n",
      "91               100         pgm2048                0\n",
      "114              100         pgm2048                0\n",
      "92               100          pgm256                0\n",
      "109              100          pgm256                0\n",
      "123              100          pgm256                0\n",
      "9                100  standard_merge                0\n",
      "68               100  standard_merge                0\n",
      "120              100  standard_merge                0\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "result_checksum = (test_dataframe[['spec.common_key', 'spec.algo_name', 'result.checksum']].sort_values(by=['spec.common_key', 'spec.algo_name'])) #.loc[test_dataframe['spec.common_key']=='10'])\n",
    "for common_key in sorted(test_dataframe['spec.common_key'].unique()):\n",
    "    checksums = result_checksum.loc[result_checksum['spec.common_key'] == common_key]\n",
    "    unique_checksums = checksums['result.checksum'].unique()\n",
    "    if (len(unique_checksums) == 1):\n",
    "        print(f\"common_key: {common_key} checksum: {unique_checksums} OK\")\n",
    "    else:\n",
    "        print(f\"common_key: {common_key} checksums don't match\")\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 100])\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 100]['result.checksum'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
