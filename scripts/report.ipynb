{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/chesetti/Repos/KVector_Merge/sponge/merge_lognormal_8/outputs/results/run']\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "import json;\n",
    "import builtins\n",
    "import pandas as pd;\n",
    "\n",
    "dir = '/home/chesetti/Repos/KVector_Merge/sponge'\n",
    "testcase = 'join_books_8'\n",
    "test_dir = os.path.join(dir, testcase)\n",
    "results_dir = os.path.join(test_dir, 'outputs', 'results')\n",
    "csv_dir = os.path.join(test_dir, 'csv')\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "runs = [os.path.join(results_dir, run) for run in os.listdir(results_dir)]\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['command', 'run', 'result.checksum', 'result.duration_ns',\n",
      "       'result.duration_sec', 'result.inner_disk_fetch',\n",
      "       'result.inner_disk_fetch_size', 'result.inner_total_bytes_fetched',\n",
      "       'result.outer_disk_fetch', 'result.outer_disk_fetch_size',\n",
      "       'result.outer_total_bytes_fetched', 'spec.algo', 'spec.algo_name',\n",
      "       'spec.common_key', 'spec.index.leaf_size_in_pages', 'spec.index.search',\n",
      "       'spec.index.type', 'spec.inner_table', 'spec.key_size', 'spec.key_type',\n",
      "       'spec.load_sstable_in_mem', 'spec.name', 'spec.num_threads',\n",
      "       'spec.outer_table', 'spec.result_path', 'spec.value_size',\n",
      "       'spec.write_result_to_disk'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Walk all the json files and put them in a dataframe\n",
    "\n",
    "test_results = []\n",
    "for run in runs:\n",
    "    for test_result_file in os.listdir(run):\n",
    "        json_file = builtins.open(os.path.join(run, test_result_file))\n",
    "        test_result = json.load(json_file)\n",
    "        test_result['run'] = run\n",
    "        test_results.append(test_result)\n",
    "        json_file.close()\n",
    "test_dataframe = pd.json_normalize(test_results)\n",
    "print(test_dataframe.columns)\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['btree1024', 'btree2048', 'btree256', 'pgm1024', 'pgm2048', 'pgm256',\n",
      "       'standard_merge'],\n",
      "      dtype='object', name='spec.algo_name')\n",
      "Int64Index([10, 20, 30, 40, 50, 60, 70, 80, 90, 100], dtype='int64', name='spec.common_key')\n",
      "spec.algo_name    btree1024   btree2048    btree256     pgm1024     pgm2048  \\\n",
      "spec.common_key                                                               \n",
      "10               2150067029  2185985051  2169116812  2121462013  2151303531   \n",
      "20               2046907549  2040639002  2067968591  2027088874  2034082340   \n",
      "30               1993928094  2022156592  2041891828  2009876658  2028422468   \n",
      "40               1965946730  1948634812  1985065876  1950886641  1950735440   \n",
      "50               1994644546  2012543086  2000789825  1967830211  1984854432   \n",
      "60               1963545049  1942207121  1962511127  1973910396  1931466651   \n",
      "70               2003318268  1952639341  1972995793  1981577570  1967813132   \n",
      "80               1927669763  1941566412  1959918315  1985754564  1991971215   \n",
      "90               1928632963  1977778967  1969270712  1927511046  1956783057   \n",
      "100              1984749416  1961559065  1981197837  1927963521  1991986639   \n",
      "\n",
      "spec.algo_name       pgm256  standard_merge  \n",
      "spec.common_key                              \n",
      "10               2128363018      2223362380  \n",
      "20               2069241134      2156508302  \n",
      "30               2039887915      2133727103  \n",
      "40               1951418582      2113756170  \n",
      "50               1981914801      2108338380  \n",
      "60               1981051748      2027973046  \n",
      "70               1958200973      2086918794  \n",
      "80               1943458023      2030819257  \n",
      "90               1937000525      2058349404  \n",
      "100              1963652608      2030792027  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor column in throughput.columns:\\n    throughput[column] = (200_000_000/throughput.index) * (1000_000_000.0 / throughput[column])\\n    throughput[column +\"_sj-rel\"] = (throughput[column] - throughput[\"sj\"] / throughput[\"sj\"]) * 100.0\\nprint(throughput)\\noverall_duration[[\"btree2048\", \"btree1024\", \"btree256\", \"sj\"]].plot() \\noverall_duration[[\"pgm128\", \"pgm512\", \"pgm1024\", \"sj\"]].plot() \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_duration = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.duration_ns', aggfunc='median')\n",
    "overall_duration.to_csv(os.path.join(csv_dir, 'duration_sec.csv'))\n",
    "print(overall_duration.columns)\n",
    "print(overall_duration.index)\n",
    "print(overall_duration)\n",
    "throughput = overall_duration\n",
    "'''\n",
    "for column in throughput.columns:\n",
    "    throughput[column] = (200_000_000/throughput.index) * (1000_000_000.0 / throughput[column])\n",
    "    throughput[column +\"_sj-rel\"] = (throughput[column] - throughput[\"sj\"] / throughput[\"sj\"]) * 100.0\n",
    "print(throughput)\n",
    "overall_duration[[\"btree2048\", \"btree1024\", \"btree256\", \"sj\"]].plot() \n",
    "overall_duration[[\"pgm128\", \"pgm512\", \"pgm1024\", \"sj\"]].plot() \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'result.inner_index_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m         epsilon\u001b[39m=\u001b[39m\u001b[39m257\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mepsilon\u001b[39m\u001b[39m\"\u001b[39m: epsilon}\n\u001b[0;32m---> 25\u001b[0m inner_index_size \u001b[39m=\u001b[39m test_dataframe\u001b[39m.\u001b[39;49mpivot_table(index\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspec.common_key\u001b[39;49m\u001b[39m'\u001b[39;49m, columns\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspec.algo_name\u001b[39;49m\u001b[39m'\u001b[39;49m, values\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mresult.inner_index_size\u001b[39;49m\u001b[39m'\u001b[39;49m, aggfunc\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmedian\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mselect c1,sum(c2), group by c1 from table\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m test_dataframe\u001b[39m.\u001b[39mfilter([\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mgroup_by(c1, )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:8728\u001b[0m, in \u001b[0;36mDataFrame.pivot_table\u001b[0;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m   8711\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8712\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   8713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpivot_table\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8724\u001b[0m     sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   8725\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   8726\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpivot\u001b[39;00m \u001b[39mimport\u001b[39;00m pivot_table\n\u001b[0;32m-> 8728\u001b[0m     \u001b[39mreturn\u001b[39;00m pivot_table(\n\u001b[1;32m   8729\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8730\u001b[0m         values\u001b[39m=\u001b[39;49mvalues,\n\u001b[1;32m   8731\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   8732\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   8733\u001b[0m         aggfunc\u001b[39m=\u001b[39;49maggfunc,\n\u001b[1;32m   8734\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m   8735\u001b[0m         margins\u001b[39m=\u001b[39;49mmargins,\n\u001b[1;32m   8736\u001b[0m         dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8737\u001b[0m         margins_name\u001b[39m=\u001b[39;49mmargins_name,\n\u001b[1;32m   8738\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8739\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8740\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/pivot.py:97\u001b[0m, in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m     94\u001b[0m     table \u001b[39m=\u001b[39m concat(pieces, keys\u001b[39m=\u001b[39mkeys, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m table \u001b[39m=\u001b[39m __internal_pivot_table(\n\u001b[1;32m     98\u001b[0m     data,\n\u001b[1;32m     99\u001b[0m     values,\n\u001b[1;32m    100\u001b[0m     index,\n\u001b[1;32m    101\u001b[0m     columns,\n\u001b[1;32m    102\u001b[0m     aggfunc,\n\u001b[1;32m    103\u001b[0m     fill_value,\n\u001b[1;32m    104\u001b[0m     margins,\n\u001b[1;32m    105\u001b[0m     dropna,\n\u001b[1;32m    106\u001b[0m     margins_name,\n\u001b[1;32m    107\u001b[0m     observed,\n\u001b[1;32m    108\u001b[0m     sort,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/pivot.py:143\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m values:\n\u001b[1;32m    142\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m data:\n\u001b[0;32m--> 143\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(i)\n\u001b[1;32m    145\u001b[0m to_filter \u001b[39m=\u001b[39m []\n\u001b[1;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m keys \u001b[39m+\u001b[39m values:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'result.inner_index_size'"
     ]
    }
   ],
   "source": [
    "def parseIndexName(name):\n",
    "    index = name\n",
    "    epsilon = 0\n",
    "    if name==\"btree1024\":\n",
    "        index=\"BTree\"\n",
    "        epsilon=1024\n",
    "    if name==\"btree2048\":\n",
    "        index=\"BTree\"\n",
    "        epsilon=2048\n",
    "    if name==\"btree256\":\n",
    "        index=\"BTree\"\n",
    "        epsilon=256\n",
    "    if name==\"pgm1024\":\n",
    "        index=\"PGM\"\n",
    "        epsilon=2049\n",
    "    if name==\"pgm512\":\n",
    "        index=\"PGM\"\n",
    "        epsilon=1025\n",
    "    if name==\"pgm128\":\n",
    "        index=\"PGM\"\n",
    "        epsilon=257\n",
    "    return {\"name\": index, \"epsilon\": epsilon}\n",
    "\n",
    "\n",
    "inner_index_size = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_index_size', aggfunc='median')\n",
    "\"select c1,sum(c2), group by c1 from table\"\n",
    "test_dataframe.filter([\"\"]).group_by(c1, )\n",
    "\n",
    "data_by_epsilon = []\n",
    "data = {}\n",
    "data['indexes'] = []\n",
    "data['memory_bytes'] = []\n",
    "for index in inner_index_size:\n",
    "    data['indexes'].append(index)\n",
    "    data['memory_bytes'].append(inner_index_size[index].mean())\n",
    "    index_dict = parseIndexName(index)\n",
    "    index_dict['memory'] = inner_index_size[index].mean()\n",
    "    data_by_epsilon.append(index_dict)\n",
    "inner_index_size = pd.DataFrame(data=data)\n",
    "inner_index_size.to_csv(os.path.join(csv_dir, 'inner_index_size.csv'))\n",
    "print(inner_index_size)\n",
    "inner_index_size_by_eps = pd.DataFrame(data_by_epsilon).pivot(index='epsilon', columns='name',values='memory')\n",
    "inner_index_size_by_eps.to_csv(os.path.join(csv_dir, 'inner_index_size_by_eps.csv'))\n",
    "print(inner_index_size_by_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'result.inner_index_build_duration_ns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inner_index_build_duration \u001b[39m=\u001b[39m test_dataframe\u001b[39m.\u001b[39;49mpivot_table(index\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspec.common_key\u001b[39;49m\u001b[39m'\u001b[39;49m, columns\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspec.algo_name\u001b[39;49m\u001b[39m'\u001b[39;49m, values\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mresult.inner_index_build_duration_ns\u001b[39;49m\u001b[39m'\u001b[39;49m, aggfunc\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmedian\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m data_by_epsilon \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m data \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:8728\u001b[0m, in \u001b[0;36mDataFrame.pivot_table\u001b[0;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m   8711\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8712\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   8713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpivot_table\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8724\u001b[0m     sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   8725\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   8726\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpivot\u001b[39;00m \u001b[39mimport\u001b[39;00m pivot_table\n\u001b[0;32m-> 8728\u001b[0m     \u001b[39mreturn\u001b[39;00m pivot_table(\n\u001b[1;32m   8729\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8730\u001b[0m         values\u001b[39m=\u001b[39;49mvalues,\n\u001b[1;32m   8731\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   8732\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   8733\u001b[0m         aggfunc\u001b[39m=\u001b[39;49maggfunc,\n\u001b[1;32m   8734\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m   8735\u001b[0m         margins\u001b[39m=\u001b[39;49mmargins,\n\u001b[1;32m   8736\u001b[0m         dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8737\u001b[0m         margins_name\u001b[39m=\u001b[39;49mmargins_name,\n\u001b[1;32m   8738\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8739\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8740\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/pivot.py:97\u001b[0m, in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m     94\u001b[0m     table \u001b[39m=\u001b[39m concat(pieces, keys\u001b[39m=\u001b[39mkeys, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m table \u001b[39m=\u001b[39m __internal_pivot_table(\n\u001b[1;32m     98\u001b[0m     data,\n\u001b[1;32m     99\u001b[0m     values,\n\u001b[1;32m    100\u001b[0m     index,\n\u001b[1;32m    101\u001b[0m     columns,\n\u001b[1;32m    102\u001b[0m     aggfunc,\n\u001b[1;32m    103\u001b[0m     fill_value,\n\u001b[1;32m    104\u001b[0m     margins,\n\u001b[1;32m    105\u001b[0m     dropna,\n\u001b[1;32m    106\u001b[0m     margins_name,\n\u001b[1;32m    107\u001b[0m     observed,\n\u001b[1;32m    108\u001b[0m     sort,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/pivot.py:143\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m values:\n\u001b[1;32m    142\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m data:\n\u001b[0;32m--> 143\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(i)\n\u001b[1;32m    145\u001b[0m to_filter \u001b[39m=\u001b[39m []\n\u001b[1;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m keys \u001b[39m+\u001b[39m values:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'result.inner_index_build_duration_ns'"
     ]
    }
   ],
   "source": [
    "inner_index_build_duration = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_index_build_duration_ns', aggfunc='median')\n",
    "data_by_epsilon = []\n",
    "data = {}\n",
    "data['indexes'] = []\n",
    "data['build_duration'] = []\n",
    "for index in inner_index_build_duration:\n",
    "    data['indexes'].append(index)\n",
    "    data['build_duration'].append(inner_index_build_duration[index].mean())\n",
    "    index_dict = parseIndexName(index)\n",
    "    index_dict['build_duration'] = inner_index_build_duration[index].mean()\n",
    "    data_by_epsilon.append(index_dict)\n",
    "inner_index_build_duration = pd.DataFrame(data=data)\n",
    "inner_index_build_duration.to_csv(os.path.join(csv_dir, 'inner_index_build_duration_ns.csv'))\n",
    "print(inner_index_build_duration)\n",
    "inner_index_bd_by_eps = pd.DataFrame(data_by_epsilon).pivot(index='epsilon', columns='name',values='build_duration')\n",
    "inner_index_bd_by_eps.to_csv(os.path.join(csv_dir, 'inner_index_size_by_eps.csv'))\n",
    "print(inner_index_bd_by_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec.algo_name   btree1024  btree2048  btree256  pgm1024  pgm2048  pgm256  \\\n",
      "spec.common_key                                                             \n",
      "10                  195313      97657    781250   156246    86806  390456   \n",
      "50                  195313      97657    776614   156076    86786  384787   \n",
      "100                 195310      97657    721113   155420    86707  367419   \n",
      "\n",
      "spec.algo_name       sj  \n",
      "spec.common_key          \n",
      "10               781250  \n",
      "50               781250  \n",
      "100              781250  \n",
      "spec.algo_name    btree1024   btree2048    btree256     pgm1024     pgm2048  \\\n",
      "spec.common_key                                                               \n",
      "10               3200000000  3200000000  3200000000  3199904704  3199980560   \n",
      "50               3200000000  3200000000  3181010944  3196429648  3199252352   \n",
      "100              3199950848  3200000000  2953678848  3182988416  3196353008   \n",
      "\n",
      "spec.algo_name       pgm256          sj  \n",
      "spec.common_key                          \n",
      "10               3198611616  3200000000  \n",
      "50               3152171168  3200000000  \n",
      "100              3009893232  3200000000  \n",
      "spec.algo_name   btree1024  btree2048  btree256  pgm1024  pgm2048  pgm256  \\\n",
      "spec.common_key                                                             \n",
      "10                   16384      32768      4096    20480    36864    8192   \n",
      "50                   16384      32768      4096    20480    36864    8192   \n",
      "100                  16384      32768      4096    20480    36864    8192   \n",
      "\n",
      "spec.algo_name     sj  \n",
      "spec.common_key        \n",
      "10               4096  \n",
      "50               4096  \n",
      "100              4096  \n"
     ]
    }
   ],
   "source": [
    "inner_index_fetch = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_disk_fetch', aggfunc='median')\n",
    "inner_index_total_fetch = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_total_bytes_fetched', aggfunc='median')\n",
    "inner_index_fetch_size = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_disk_fetch_size', aggfunc='median')\n",
    "print(inner_index_fetch)\n",
    "print(inner_index_total_fetch)\n",
    "print(inner_index_fetch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_key: 10 checksum: ['9B57CDDD9798604CC7D3BC254D867BE9'] OK\n",
      "common_key: 50 checksum: ['BF415AFBB5A73E61F504EDC6FCCA9870'] OK\n",
      "common_key: 100 checksum: ['5B625421C7CCBDC2FF99DDCC00517618'] OK\n",
      "    spec.common_key spec.algo_name                   result.checksum\n",
      "1               100      btree1024  5B625421C7CCBDC2FF99DDCC00517618\n",
      "24              100      btree1024  5B625421C7CCBDC2FF99DDCC00517618\n",
      "34              100      btree1024  5B625421C7CCBDC2FF99DDCC00517618\n",
      "3               100      btree2048  5B625421C7CCBDC2FF99DDCC00517618\n",
      "42              100      btree2048  5B625421C7CCBDC2FF99DDCC00517618\n",
      "55              100      btree2048  5B625421C7CCBDC2FF99DDCC00517618\n",
      "6               100       btree256  5B625421C7CCBDC2FF99DDCC00517618\n",
      "8               100       btree256  5B625421C7CCBDC2FF99DDCC00517618\n",
      "61              100       btree256  5B625421C7CCBDC2FF99DDCC00517618\n",
      "10              100        pgm1024  5B625421C7CCBDC2FF99DDCC00517618\n",
      "20              100        pgm1024  5B625421C7CCBDC2FF99DDCC00517618\n",
      "52              100        pgm1024  5B625421C7CCBDC2FF99DDCC00517618\n",
      "7               100        pgm2048  5B625421C7CCBDC2FF99DDCC00517618\n",
      "31              100        pgm2048  5B625421C7CCBDC2FF99DDCC00517618\n",
      "49              100        pgm2048  5B625421C7CCBDC2FF99DDCC00517618\n",
      "26              100         pgm256  5B625421C7CCBDC2FF99DDCC00517618\n",
      "40              100         pgm256  5B625421C7CCBDC2FF99DDCC00517618\n",
      "44              100         pgm256  5B625421C7CCBDC2FF99DDCC00517618\n",
      "43              100             sj  5B625421C7CCBDC2FF99DDCC00517618\n",
      "46              100             sj  5B625421C7CCBDC2FF99DDCC00517618\n",
      "54              100             sj  5B625421C7CCBDC2FF99DDCC00517618\n",
      "['5B625421C7CCBDC2FF99DDCC00517618']\n"
     ]
    }
   ],
   "source": [
    "result_checksum = (test_dataframe[['spec.common_key', 'spec.algo_name', 'result.checksum']].sort_values(by=['spec.common_key', 'spec.algo_name'])) #.loc[test_dataframe['spec.common_key']=='10'])\n",
    "for common_key in sorted(test_dataframe['spec.common_key'].unique()):\n",
    "    checksums = result_checksum.loc[result_checksum['spec.common_key'] == common_key]\n",
    "    unique_checksums = checksums['result.checksum'].unique()\n",
    "    if (len(unique_checksums) == 1):\n",
    "        print(f\"common_key: {common_key} checksum: {unique_checksums} OK\")\n",
    "    else:\n",
    "        print(f\"common_key: {common_key} checksums don't match\")\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 100])\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 100]['result.checksum'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
