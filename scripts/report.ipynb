{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/chesetti/Repos/learned_merge_cleanup/sponge/merge_str_1/outputs/results/run']\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "import json;\n",
    "import builtins\n",
    "import pandas as pd;\n",
    "\n",
    "dir = '/home/chesetti/Repos/learned_merge_cleanup/sponge'\n",
    "testcase = 'merge_str_1'\n",
    "test_dir = os.path.join(dir, testcase)\n",
    "results_dir = os.path.join(test_dir, 'outputs', 'results')\n",
    "csv_dir = os.path.join(test_dir, 'csv')\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "runs = [os.path.join(results_dir, run) for run in os.listdir(results_dir)]\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['command', 'run', 'result.checksum', 'result.duration_ns',\n",
      "       'result.duration_sec', 'result.inner_disk_fetch',\n",
      "       'result.inner_disk_fetch_size', 'result.inner_total_bytes_fetched',\n",
      "       'result.outer_disk_fetch', 'result.outer_disk_fetch_size',\n",
      "       'result.outer_total_bytes_fetched', 'spec.algo', 'spec.algo_name',\n",
      "       'spec.common_key', 'spec.index.search', 'spec.index.type',\n",
      "       'spec.inner_table', 'spec.key_size', 'spec.key_type',\n",
      "       'spec.load_sstable_in_mem', 'spec.name', 'spec.num_threads',\n",
      "       'spec.outer_table', 'spec.result_path', 'spec.value_size',\n",
      "       'spec.write_result_to_disk', 'spec.index.leaf_size_in_pages'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Walk all the json files and put them in a dataframe\n",
    "\n",
    "test_results = []\n",
    "for run in runs:\n",
    "    for test_result_file in os.listdir(run):\n",
    "        json_file = builtins.open(os.path.join(run, test_result_file))\n",
    "        test_result = json.load(json_file)\n",
    "        test_result['run'] = run\n",
    "        test_results.append(test_result)\n",
    "        json_file.close()\n",
    "test_dataframe = pd.json_normalize(test_results)\n",
    "print(test_dataframe.columns)\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['btree1024', 'btree2048', 'btree256', 'pgm1024', 'pgm2048', 'pgm256',\n",
      "       'standard_merge'],\n",
      "      dtype='object', name='spec.algo_name')\n",
      "Index([1, 5, 10, 50, 100], dtype='int64', name='spec.common_key')\n",
      "spec.algo_name      btree1024     btree2048      btree256       pgm1024  \\\n",
      "spec.common_key                                                           \n",
      "1                         NaN           NaN           NaN           NaN   \n",
      "5                1.785659e+10  1.515691e+10  1.965494e+10  6.398384e+09   \n",
      "10               1.110211e+10  9.602647e+09  1.210193e+10  4.768641e+09   \n",
      "50               4.549987e+09  4.233646e+09  4.783735e+09  3.199191e+09   \n",
      "100              3.657186e+09  3.500125e+09  3.778569e+09  2.981610e+09   \n",
      "\n",
      "spec.algo_name        pgm2048        pgm256  standard_merge  \n",
      "spec.common_key                                              \n",
      "1                         NaN  2.949066e+09             NaN  \n",
      "5                6.333842e+09  6.523274e+09    5.241529e+09  \n",
      "10               4.757469e+09  4.912657e+09    4.694429e+09  \n",
      "50               3.170419e+09  3.243912e+09    4.236012e+09  \n",
      "100              2.956305e+09  2.997004e+09    4.181382e+09  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor column in throughput.columns:\\n    throughput[column] = (200_000_000/throughput.index) * (1000_000_000.0 / throughput[column])\\n    throughput[column +\"_sj-rel\"] = (throughput[column] - throughput[\"sj\"] / throughput[\"sj\"]) * 100.0\\nprint(throughput)\\noverall_duration[[\"btree2048\", \"btree1024\", \"btree256\", \"sj\"]].plot() \\noverall_duration[[\"pgm128\", \"pgm512\", \"pgm1024\", \"sj\"]].plot() \\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_duration = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.duration_ns', aggfunc='median')\n",
    "overall_duration.to_csv(os.path.join(csv_dir, 'duration_sec.csv'))\n",
    "print(overall_duration.columns)\n",
    "print(overall_duration.index)\n",
    "print(overall_duration)\n",
    "throughput = overall_duration\n",
    "'''\n",
    "for column in throughput.columns:\n",
    "    throughput[column] = (200_000_000/throughput.index) * (1000_000_000.0 / throughput[column])\n",
    "    throughput[column +\"_sj-rel\"] = (throughput[column] - throughput[\"sj\"] / throughput[\"sj\"]) * 100.0\n",
    "print(throughput)\n",
    "overall_duration[[\"btree2048\", \"btree1024\", \"btree256\", \"sj\"]].plot() \n",
    "overall_duration[[\"pgm128\", \"pgm512\", \"pgm1024\", \"sj\"]].plot() \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec.algo_name   btree1024  btree2048  btree256   pgm1024   pgm2048    pgm256  \\\n",
      "spec.common_key                                                                 \n",
      "1                      NaN        NaN       NaN       NaN       NaN  781250.0   \n",
      "5                 781250.0   781250.0  781250.0  781250.0  781250.0  781250.0   \n",
      "10                781250.0   781250.0  781250.0  781250.0  781250.0  781250.0   \n",
      "50                781250.0   781250.0  781250.0  781250.0  781250.0  781250.0   \n",
      "100               781250.0   781250.0  781250.0  781250.0  781250.0  781250.0   \n",
      "\n",
      "spec.algo_name   standard_merge  \n",
      "spec.common_key                  \n",
      "1                           NaN  \n",
      "5                      781250.0  \n",
      "10                     781250.0  \n",
      "50                     781250.0  \n",
      "100                    781250.0  \n",
      "spec.algo_name      btree1024     btree2048      btree256       pgm1024  \\\n",
      "spec.common_key                                                           \n",
      "1                         NaN           NaN           NaN           NaN   \n",
      "5                3.200000e+09  3.200000e+09  3.200000e+09  3.200000e+09   \n",
      "10               3.200000e+09  3.200000e+09  3.200000e+09  3.200000e+09   \n",
      "50               3.200000e+09  3.200000e+09  3.200000e+09  3.200000e+09   \n",
      "100              3.200000e+09  3.200000e+09  3.200000e+09  3.200000e+09   \n",
      "\n",
      "spec.algo_name        pgm2048        pgm256  standard_merge  \n",
      "spec.common_key                                              \n",
      "1                         NaN  3.200000e+09             NaN  \n",
      "5                3.200000e+09  3.200000e+09    3.200000e+09  \n",
      "10               3.200000e+09  3.200000e+09    3.200000e+09  \n",
      "50               3.200000e+09  3.200000e+09    3.200000e+09  \n",
      "100              3.200000e+09  3.200000e+09    3.200000e+09  \n",
      "spec.algo_name   btree1024  btree2048  btree256  pgm1024  pgm2048  pgm256  \\\n",
      "spec.common_key                                                             \n",
      "1                      NaN        NaN       NaN      NaN      NaN  4096.0   \n",
      "5                   4096.0     4096.0    4096.0   4096.0   4096.0  4096.0   \n",
      "10                  4096.0     4096.0    4096.0   4096.0   4096.0  4096.0   \n",
      "50                  4096.0     4096.0    4096.0   4096.0   4096.0  4096.0   \n",
      "100                 4096.0     4096.0    4096.0   4096.0   4096.0  4096.0   \n",
      "\n",
      "spec.algo_name   standard_merge  \n",
      "spec.common_key                  \n",
      "1                           NaN  \n",
      "5                        4096.0  \n",
      "10                       4096.0  \n",
      "50                       4096.0  \n",
      "100                      4096.0  \n"
     ]
    }
   ],
   "source": [
    "inner_index_fetch = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_disk_fetch', aggfunc='median')\n",
    "inner_index_total_fetch = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_total_bytes_fetched', aggfunc='median')\n",
    "inner_index_fetch_size = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_disk_fetch_size', aggfunc='median')\n",
    "print(inner_index_fetch)\n",
    "print(inner_index_total_fetch)\n",
    "print(inner_index_fetch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_key: 1 checksum: [0] OK\n",
      "common_key: 5 checksum: [0] OK\n",
      "common_key: 10 checksum: [0] OK\n",
      "common_key: 50 checksum: [0] OK\n",
      "common_key: 100 checksum: [0] OK\n",
      "    spec.common_key  spec.algo_name  result.checksum\n",
      "47              100       btree1024                0\n",
      "60              100       btree1024                0\n",
      "76              100       btree1024                0\n",
      "3               100       btree2048                0\n",
      "29              100       btree2048                0\n",
      "68              100       btree2048                0\n",
      "72              100        btree256                0\n",
      "77              100        btree256                0\n",
      "78              100        btree256                0\n",
      "14              100         pgm1024                0\n",
      "45              100         pgm1024                0\n",
      "50              100         pgm1024                0\n",
      "33              100         pgm2048                0\n",
      "58              100         pgm2048                0\n",
      "75              100         pgm2048                0\n",
      "59              100          pgm256                0\n",
      "71              100          pgm256                0\n",
      "83              100          pgm256                0\n",
      "8               100  standard_merge                0\n",
      "43              100  standard_merge                0\n",
      "81              100  standard_merge                0\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "result_checksum = (test_dataframe[['spec.common_key', 'spec.algo_name', 'result.checksum']].sort_values(by=['spec.common_key', 'spec.algo_name'])) #.loc[test_dataframe['spec.common_key']=='10'])\n",
    "for common_key in sorted(test_dataframe['spec.common_key'].unique()):\n",
    "    checksums = result_checksum.loc[result_checksum['spec.common_key'] == common_key]\n",
    "    unique_checksums = checksums['result.checksum'].unique()\n",
    "    if (len(unique_checksums) == 1):\n",
    "        print(f\"common_key: {common_key} checksum: {unique_checksums} OK\")\n",
    "    else:\n",
    "        print(f\"common_key: {common_key} checksums don't match\")\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 100])\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 100]['result.checksum'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
