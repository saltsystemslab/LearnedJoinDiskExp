{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/chesetti/Repos/learned_merge_cleanup/sponge/eps_study/join_fb_1/outputs/results/run']\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "import json;\n",
    "import builtins\n",
    "import pandas as pd;\n",
    "\n",
    "dir = '/home/chesetti/Repos/learned_merge_cleanup/sponge'\n",
    "testcase = 'eps_study/join_fb_1'\n",
    "test_dir = os.path.join(dir, testcase)\n",
    "results_dir = os.path.join(test_dir, 'outputs', 'results')\n",
    "csv_dir = os.path.join(test_dir, 'csv')\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "runs = [os.path.join(results_dir, run) for run in os.listdir(results_dir)]\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['command', 'run', 'result.checksum', 'result.duration_ns',\n",
      "       'result.duration_sec', 'result.inner_disk_fetch',\n",
      "       'result.inner_disk_fetch_size', 'result.inner_total_bytes_fetched',\n",
      "       'result.outer_disk_fetch', 'result.outer_disk_fetch_size',\n",
      "       'result.outer_total_bytes_fetched', 'spec.algo', 'spec.algo_name',\n",
      "       'spec.check_checksum', 'spec.common_key', 'spec.index.search',\n",
      "       'spec.index.type', 'spec.inner_table', 'spec.key_size', 'spec.key_type',\n",
      "       'spec.load_sstable_in_mem', 'spec.name', 'spec.num_threads',\n",
      "       'spec.outer_table', 'spec.result_path', 'spec.value_size',\n",
      "       'spec.write_result_to_disk'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Walk all the json files and put them in a dataframe\n",
    "\n",
    "test_results = []\n",
    "for run in runs:\n",
    "    for test_result_file in os.listdir(run):\n",
    "        json_file = builtins.open(os.path.join(run, test_result_file))\n",
    "        test_result = json.load(json_file)\n",
    "        test_result['run'] = run\n",
    "        test_results.append(test_result)\n",
    "        json_file.close()\n",
    "test_dataframe = pd.json_normalize(test_results)\n",
    "print(test_dataframe.columns)\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['flatpgm1024', 'flatpgm2048', 'flatpgm256', 'flatpgm4096',\n",
      "       'flatpgm8192', 'sj'],\n",
      "      dtype='object', name='spec.algo_name')\n",
      "Index([1, 10, 100, 1000], dtype='int64', name='spec.common_key')\n",
      "|   spec.common_key |   flatpgm1024 |   flatpgm2048 |   flatpgm256 |   flatpgm4096 |   flatpgm8192 |          sj |\n",
      "|------------------:|--------------:|--------------:|-------------:|--------------:|--------------:|------------:|\n",
      "|                 1 |   1.17219e+09 |   1.79725e+09 |  1.06313e+09 |   1.28248e+09 |   1.34946e+09 | 5.80793e+08 |\n",
      "|                10 |   1.79187e+08 |   1.81795e+08 |  1.64653e+08 |   1.88454e+08 |   1.82988e+08 | 2.02129e+08 |\n",
      "|               100 |   5.53367e+07 |   5.63119e+07 |  5.28592e+07 |   6.09474e+07 |   5.35882e+07 | 1.57892e+08 |\n",
      "|              1000 |   2.68736e+07 |   2.35769e+07 |  1.55118e+07 |   3.90226e+07 |   3.95034e+07 | 1.50613e+08 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor column in throughput.columns:\\n    throughput[column] = (200_000_000/throughput.index) * (1000_000_000.0 / throughput[column])\\n    throughput[column +\"_sj-rel\"] = (throughput[column] - throughput[\"sj\"] / throughput[\"sj\"]) * 100.0\\nprint(throughput)\\noverall_duration[[\"btree2048\", \"btree1024\", \"btree256\", \"sj\"]].plot() \\noverall_duration[[\"pgm128\", \"pgm512\", \"pgm1024\", \"sj\"]].plot() \\n'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_duration = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.duration_ns', aggfunc='median')\n",
    "overall_duration.to_csv(os.path.join(csv_dir, 'duration_sec.csv'))\n",
    "print(overall_duration.columns)\n",
    "print(overall_duration.index)\n",
    "throughput = overall_duration\n",
    "print(throughput.to_markdown())\n",
    "throughput.plot()\n",
    "'''\n",
    "for column in throughput.columns:\n",
    "    throughput[column] = (200_000_000/throughput.index) * (1000_000_000.0 / throughput[column])\n",
    "    throughput[column +\"_sj-rel\"] = (throughput[column] - throughput[\"sj\"] / throughput[\"sj\"]) * 100.0\n",
    "print(throughput)\n",
    "overall_duration[[\"btree2048\", \"btree1024\", \"btree256\", \"sj\"]].plot() \n",
    "overall_duration[[\"pgm128\", \"pgm512\", \"pgm1024\", \"sj\"]].plot() \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec.algo_name   flatpgm1024  flatpgm2048  flatpgm256  flatpgm4096  \\\n",
      "spec.common_key                                                      \n",
      "1                  156066576    156066576   156066480    156066576   \n",
      "10                 156065664    156066496   156040016    156066576   \n",
      "100                155578288    156015680   147398016    156062896   \n",
      "1000               107110400    134701056    58630144    150471248   \n",
      "\n",
      "spec.algo_name   flatpgm8192         sj  \n",
      "spec.common_key                          \n",
      "1                  156066576  156066576  \n",
      "10                 156066576  156066576  \n",
      "100                156064992  156065792  \n",
      "1000               155116528  156057600  \n"
     ]
    }
   ],
   "source": [
    "inner_index_fetch = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_disk_fetch', aggfunc='median')\n",
    "inner_index_total_fetch = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_total_bytes_fetched', aggfunc='median')\n",
    "inner_index_fetch_size = test_dataframe.pivot_table(index='spec.common_key', columns='spec.algo_name', values='result.inner_disk_fetch_size', aggfunc='median')\n",
    "print(inner_index_total_fetch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_key: 1 checksum: ['D1870CC3EEAA3EE0262727AEC635A778'] OK\n",
      "common_key: 10 checksum: ['9A10FE3267020EC7AE4F7CBC74860473'] OK\n",
      "common_key: 100 checksum: ['0396A0E8E9B3A43C2FE141DF494ADB32'] OK\n",
      "common_key: 1000 checksum: ['F952146E48E1C1B8212BB7CE2C5CFBFE'] OK\n",
      "    spec.common_key spec.algo_name                   result.checksum\n",
      "10              100    flatpgm1024  0396A0E8E9B3A43C2FE141DF494ADB32\n",
      "20              100    flatpgm2048  0396A0E8E9B3A43C2FE141DF494ADB32\n",
      "9               100     flatpgm256  0396A0E8E9B3A43C2FE141DF494ADB32\n",
      "12              100    flatpgm4096  0396A0E8E9B3A43C2FE141DF494ADB32\n",
      "19              100    flatpgm8192  0396A0E8E9B3A43C2FE141DF494ADB32\n",
      "4               100             sj  0396A0E8E9B3A43C2FE141DF494ADB32\n",
      "['0396A0E8E9B3A43C2FE141DF494ADB32']\n"
     ]
    }
   ],
   "source": [
    "result_checksum = (test_dataframe[['spec.common_key', 'spec.algo_name', 'result.checksum']].sort_values(by=['spec.common_key', 'spec.algo_name'])) #.loc[test_dataframe['spec.common_key']=='10'])\n",
    "for common_key in sorted(test_dataframe['spec.common_key'].unique()):\n",
    "    checksums = result_checksum.loc[result_checksum['spec.common_key'] == common_key]\n",
    "    unique_checksums = checksums['result.checksum'].unique()\n",
    "    if (len(unique_checksums) == 1):\n",
    "        print(f\"common_key: {common_key} checksum: {unique_checksums} OK\")\n",
    "    else:\n",
    "        print(f\"common_key: {common_key} checksums don't match\")\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 100])\n",
    "print(result_checksum.loc[result_checksum['spec.common_key'] == 100]['result.checksum'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
